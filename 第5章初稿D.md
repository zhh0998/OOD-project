\chapter{CP-ABR++：一种级联因果图驱动的鲁棒文本OOD检测方法}

\section{引言}\label{sec:intro}
 近年来，分布外检测（Out-of-Distribution Detection, OOD）在文本理解领域受到广泛关注。这一任务旨在识别出那些不属于模型训练时所见类别的输入，对于开放世界的自然语言处理系统至关重要。现有大量研究在该方向取得了显著进展，提出了从基于判别模型的置信度分析到基于生成模型的概率估计等多种方法。然而，这些主流方法（尤其是依赖大规模预训练语言模型（Large Language Model, LLM）的方案）在处理复杂的文本OOD场景时仍存在根本性缺陷。首先，许多方法过度依赖表层的词汇或语义相似度特征，例如仅根据句子的平均嵌入距离或分类器的最大Softmax概率来判定OOD。这种策略忽视了深层的语义结构和概念关系，因而在“近OOD”场景（语义上与已知类别接近但本质属于未知的新类别）下常常失效：模型容易将细粒度的新意图误判为训练集中相似的意图，从而导致性能急剧下降。其次，LLM生成式的方法虽然具备一定的常识推理能力，但由于缺乏专门设计的机制，它们可能会在面对语义偏移时产生错误的高置信度判断，即所谓的过度自信问题。这些方法往往无法识别出输入中隐藏的细微语义差异，尤其当OOD样本伪装得与ID样本“看起来”相似时，模型容易被欺骗。这些缺陷在实际应用中会带来严重的安全隐患：模型可能对未见过的新意图给出毫无依据的确定答案。

为深入剖析上述问题，我们从两个角度对文本OOD检测挑战进行分析。其一是\textbf{语义偏移 vs. 协变量偏移}。协变量偏移指训练和测试数据的输入分布发生变化，但标签空间保持不变；在文本领域典型案例如模型在新闻语料上训练却用于社交媒体文本。然而，语义偏移才是OOD检测关注的核心：测试样本来自训练时未包含的新语义类别。对于意图识别系统而言，这意味着用户提出了训练集中不存在的新意图请求。语义偏移要求模型不仅辨别分布差异，更要觉察完全陌生的语义。这比协变量偏移困难得多：后者可以通过领域自适应等技术缓解，而前者本质上属于开放空间风险，模型必须在无监督条件下自主发现“未知”。其二是\textbf{近OOD vs. 远OOD}的区分。近OOD样本在语义上与训练类簇接近，例如在银行意图识别系统中，一个未见过的意图“申请信用卡”与已知意图“借记卡激活”属于同一业务范畴；远OOD样本则来自完全不同领域，如银行系统收到天气询问属于远OOD。近OOD更具迷惑性，因为它们位于已知类别流形的边缘，容易与ID样本混淆。远OOD则通常在表面上就与ID内容差异明显，传统方法对远OOD往往表现较好，但在近OOD上错误率很高。我们进一步注意到，在LLM部署的实际环境中，还存在一种特殊的OOD场景：\textbf{对抗性和隐式OOD输入}。这类输入在技术上属于OOD，但经过精心设计，具有对抗性或隐蔽性，旨在误导模型。例如，一段话语表面中性，但通过隐含的组合表达了仇恨言论。ToxiGen数据集正是针对这一问题构造的大规模基准，包含由GPT-3生成的大量微妙有毒与良性陈述，以测试模型对隐蔽分布外内容的抵抗力。如果现有模型仅凭表面特征判断，它们很可能错将这些隐蔽有害输入当作正常域内，埋下安全隐患。

基于以上分析，我们的研究动机是设计一种新的OOD检测方法，能够从\textbf{语义结构建模}和\textbf{决策边界扩展}两方面入手，弥补当前方法的不足。本章提出的**CP-ABR++**模型正是针对上述痛点而生。我们认识到，仅依赖输入句子的孤立表示无法充分判别细粒度语义差异，因而\emph{引入显式的语义关系图谱}来增强表示：通过挖掘样本与样本之间、样本与知识概念之间的因果关联，我们期望模型能够识别出OOD样本在语义网络中“缺失”或“断裂”的关键环节。此外，对于靠近已知决策边界的疑难样本，我们\emph{引入自适应生成的探针样本}主动攻击模型，使模型在训练过程中不断暴露并加固自身薄弱区域，从而提高对近OOD的鉴别力。理论上，语义图能够提供超出单个句子的上下文与常识约束，使模型的表示空间具有因果一致性和更紧凑的类内结构；而生成式探针则相当于在模型决策边界附近添加“哨兵”，迫使模型学会将已知类别与未知空间明确分离。结合这两点，我们有望大幅提高模型在各种OOD场景下的鲁棒性，并减少误判的发生率。

本章工作的核心贡献如下所示：

- **首先**，我们创新性地提出了一种融合\textbf{因果语义图谱}与\textbf{生成式模型}的OOD检测框架CP-ABR++。本方法首次将\emph{显式图结构建模}引入文本OOD检测任务，通过构建语义关系图刻画样本间深层语义关联，有效解决了现有方法忽视语义结构导致的细粒度混淆问题。
- **其次**，我们设计了一个\textbf{自适应探针生成模块}，能够基于模型当前的决策边界动态地产生多样性的“探针”样本。从而在训练过程中不断挑战并扩大模型的决策边界，显著提升模型对\textbf{近OOD}样本的辨别能力和开放空间下的泛化性能。
- **第三**，我们在多个具有挑战性的基准数据集上进行了广泛的实验，包括跨领域的**CLINC150**、细粒度单领域的**Banking77**、真实用户查询的**ROSTD**以及对抗性样本集**ToxiGen**。结果表明，我们的方法在主要评测指标（如AUROC、FPR$_{95}$等）上均显著优于现有最新SOTA模型，取得了当前最优的检测性能。
- **第四**，我们通过深入的消融研究和案例分析，验证了各个创新模块的必要性与有效性。具体而言，移除语义图谱将导致检测性能大幅下降，证明显式建模样本关系对区分近OOD至关重要；移除探针生成模块亦会降低模型对边界样本的鲁棒性。此外，我们提供了模型决策过程的结构化**忠实解释**，通过证据链分析展示了CP-ABR++如何做出判断，进一步增强了模型的可解释性和可信度。

为了直观展示本章方法的有效性，我们在引言中特别设计了一幅“直觉图”来对比引入本方法前后，模型表示空间的变化。如图\ref{fig:intuition}所示，该图形象地揭示了**为什么**我们的CP-ABR++模型能够提升OOD检测性能：在引入语义图谱和生成探针之前，ID与OOD样本在表示空间中往往纠缠在一起；而采用我们的方法后，表示空间得到重塑，ID与OOD的边界变得清晰可分。

\begin{figure}[t]
 \centering
 \caption{CP-ABR++模型通过构建语义结构图重塑表示空间的直觉示意图。（左）传统方法下的表示空间：二维投影中，蓝色圆点表示ID样本，红色三角表示近OOD样本，灰色叉表示远OOD样本。可以看到，蓝色点虽然大致聚类但内部松散，且与红色三角大量重叠，边界模糊，说明现有方法难以区分细粒度语义差异。（右）CP-ABR++方法下的表示空间：蓝色ID样本被紧密拉拢，形成数个紧凑簇；红色近OOD样本被清晰地推离蓝色簇，形成独立的小簇；灰色远OOD样本则远远分散在边缘地带。蓝色簇与红色/灰色区域之间用虚线标示出清晰的决策边界。从左到右的箭头标注“应用CP-ABR++模型”，表示这种空间重构归功于我们方法的作用。（此图设计灵感源自在CLINC150数据集上对[CLS]向量进行t-SNE可视化的预实验结果，旨在直观展示CP-ABR++通过增强类内紧凑性和类间分离性来提升OOD检测性能。图表风格简洁明了，符合学术论文中的信息图规范。）}
 \label{fig:intuition}
 \end{figure}

\section{方法设计}\label{sec:method}

\subsection{问题形式化}\label{sec:formulation}
 文本分布外检测任务可以形式化定义如下：给定一个仅包含分布内（In-Distribution, ID）类别的有标签训练集$\mathcal{D}*{\text{train}}={(x_i, y_i)}*{i=1}^{N}$，其中$x_i$表示输入文本（通常为一句用户请求或句子级文本），$y_i \in \mathcal{Y}*{\text{ID}}$表示对应的已知意图标签类别（$|\mathcal{Y}*{\text{ID}}|=C$类）。模型训练仅利用$\mathcal{D}*{\text{train}}$中的ID样本，不接触任何OOD样本。在测试时，对于任一输入文本$x*{\text{test}}$，模型需要判断其是否属于训练时的已知意图之一；如果是，则输出对应的意图类别$\hat{y}\in \mathcal{Y}_{\text{ID}}$，如果不是（即OOD样本），则应当将其标记为“OOD”。因为OOD样本在训练阶段不可用且种类未知，我们要求模型在\textbf{无监督}的条件下完成上述检测。在这一过程中，我们关注模型的以下性能目标：

- \textbf{高效性}：模型应具有较低的平均推理计算成本，能够快速处理大规模请求流。这通常要求在保持性能的前提下，尽可能减少对复杂子模块的调用次数。
- \textbf{鲁棒性}：模型在不同类型的OOD场景下（包括近OOD和远OOD，以及隐含对抗性输入）都能保持稳定的检测性能，避免出现某些场景下性能骤降的情况。
- \textbf{可信性与可解释性}：模型给出的OOD判定应伴有人类可理解的依据。也就是说，模型不仅要告诉我们一个样本是OOD，还需要能够解释为什么它被视为OOD，以增强决策的可信度。

更形式地，可以定义一个检测判别函数$g(x): \mathcal{X}\rightarrow {\text{ID}}\cup{\text{OOD}}$，以及一个分类函数$f(x): \mathcal{X}\rightarrow \mathcal{Y}*{\text{ID}}$。我们希望训练一个联合模型，使得对于任意测试输入$x*{\text{test}}$：

g(xtest)={ID,若 xtest属于已知分布，即 ∃y∈YID,f(xtest)=y,OOD,若 xtest不属于任何已知类别.g(x_{\text{test}}) =  \begin{cases} \text{ID}, & \text{若 } x_{\text{test}} \text{属于已知分布，即 } \exists y\in \mathcal{Y}_{\text{ID}}, f(x_{\text{test}})=y, \\ \text{OOD}, & \text{若 } x_{\text{test}} \text{不属于任何已知类别}. \end{cases}

同时，对于$g(x_{\text{test}})=\text{ID}$的情形，$f(x_{\text{test}})$应输出正确的意图类别。由于无监督设置下无法获取真实的OOD样本标签，我们通常以训练集中ID样本的分布作为参考，通过模型对测试样本的\textbf{异常分数}（anomaly score）或不确定性来判定其是否为OOD。具体判定策略后文将详细描述。

\subsection{模型总体架构}\label{sec:architecture}
 如图\ref{fig:architecture}所示，本章提出的CP-ABR++模型采用级联判别与生成相结合的整体架构，包含五个主要阶段（Stage-0至Stage-4），以逐步筛选、增强和解释输入样本的OOD属性。模型从左到右处理数据流：首先经过一个文本编码器提取初步表示，再通过因果语义图谱模块和图表示学习模块获得增强的鲁棒表示，随后利用生成式探针和条件流模型对样本进行OOD判定，最后如果样本被判为OOD则触发证据链解释生成模块。各模块的功能和衔接如下：

- **Stage-0：级联能量门** – 快速筛选低不确定性样本。输入文本先经过**文本编码器**（Text Encoder，例如BERT等预训练模型）得到隐藏表示和分类logits，计算其能量分数$E(x)$。若$E(x)$低于设定阈值$\tau_E$，则模型以高置信度认为样本属于ID并直接输出分类结果，无需执行后续复杂流程；若$E(x)\ge \tau_E$，则视样本为潜在OOD，进入下一阶段深度处理。
- **Stage-1：因果语义图构建** – 建立样本与知识的关系图并提取强化表示。对于Stage-0筛出的疑难样本，首先利用LLM结合训练集$\mathcal{D}*{\text{train}}$及外部知识库自动\textbf{构建一个语义因果图}$G=(V, E, W)$，节点表示语句及相关概念，边表示因果或语义关联，权重$W$表示可信度。为降低LLM生成幻觉，我们内置自检机制剔除低可靠性边。然后，将当前输入样本节点嵌入此图中，采用**图神经网络**（Graph Neural Network, GNN）聚合邻居信息，计算得到鲁棒的样本表示$\mathbf{h}*{*}$，包含丰富的上下文和常识关系信息。
- **Stage-2：自适应探针生成** – 主动探索模型决策边界附近的空间。基于强化表示$\mathbf{h}*{\*}$和现有模型判别边界，我们使用生成模型（如条件扩散模型或GAN）**动态生成一组探针样本**${x*{\text{probe}}}$。这些探针旨在模拟“最难判”的潜在OOD样本。通过引入对抗性损失$\mathcal{L}*{\text{adv}}$鼓励生成样本让现有模型产生误判，以及多样性损失$\mathcal{L}*{\text{div}}$避免生成模式坍塌，我们自适应调整探针的生成策略。生成的探针将用于训练中强化模型边界，使其更好地区分靠近ID的OOD样本。
- **Stage-3：多模态条件流检测** – 基于生成式概率模型进行OOD判定。我们采用\textbf{条件正态化流}（Conditional Normalizing Flow, CNF）模型作为最终的OOD评分模块。该流模型以样本自身特征和Stage-1得到的条件表示$\mathbf{h}_{*}$为输入，学习ID数据的概率密度$p_X(x)$。我们改进传统流模型使用单峰先验的局限，采用**高斯混合模型（GMM）**作为潜在空间多模态先验：

\begin{equation}
 p_Z(z) = \sum_{k=1}^{K} \pi_k \mathcal{N}(z \mid \mu_k, \Sigma_k),
 \label{eq:gmm-prior}
 \end{equation}

其中$z$是流模型将$x$映射到潜空间的表示，$\mathcal{N}(z|\mu_k,\Sigma_k)$为第$k$个高斯成分，$\pi_k$为混合系数（$\sum_k \pi_k=1$）。该多模态先验能够更好地拟合复杂数据分布，避免流模型在训练数据未覆盖区域产生高置信度误判。本阶段训练时，我们引入探针样本的“排斥”损失$\mathcal{L}_{\text{repel}}$，降低模型在生成探针上的密度估计值，从而将这些潜在OOD样本排斥出ID密度集中区域。最终，模型依据负对数似然定义异常分数：

\begin{equation}
 s(x) = -\log,p_X(x),
 \label{eq:score}
 \end{equation}

其中$p_X(x)$由流模型计算得到。给定阈值$\tau_s$，若$s(x)>\tau_s$则判定$x$为OOD，否则为ID。需要注意的是，我们的OOD评分模块综合利用了\textbf{两方面信息}：一是传统分类分支提供的判别线索（例如能量分数或Softmax输出），二是流模型提供的生成式似然。模型可以将二者融合以提高判别的可靠性（例如通过简单加权或训练一个线性层将它们组合）。在实验中，我们发现利用二者的加权和作为最终分数可以取得最佳效果。

- **Stage-4：证据链解释生成** – 为判定为OOD的输入提供结构化的可解释原因。当模型将$x_{\text{test}}$判为OOD时，我们启动解释模块以生成人类可读的解释文本。该模块综合利用Stage-1和Stage-3中间生成的信息：首先从因果语义图中提取最显著的\textbf{关系断裂}作为因果证据A（例如，输入涉及的某关键概念在语义图中无连接或只连接到弱相关节点）；其次从流模型的潜在空间分析中获取\textbf{概率异常}证据B（例如，样本在某主成分上偏离ID分布的程度最大）。然后，我们设计预定义的模板，将证据A和B填入其中，并通过一个预训练LLM将其润色为流畅的自然语言解释。输出的解释包含了最主要的判别依据，如“输入涉及了训练未见过的概念X，且其生成概率极低，因此被判为OOD”等。整个过程确保解释与模型决策过程\textbf{忠实一致}：每一条解释都可溯源到模型内部的具体因素（图结构断裂或概率骤降），避免臆造无关的信息，从而提升用户对模型判断的信任。

\begin{figure}[t]
 \centering
 \caption{CP-ABR++模型的总体架构示意图。整个流程由左至右：最左侧是输入文本，经由文本编码器（如BERT）提取出文本表示和初始判别分数。一方面，该表示直接送入OOD评分模块（箭头向上），为最终判别提供判别式线索；另一方面，该表示送入语义图构建模块（箭头向下），结合训练数据和知识库生成当前输入的因果语义关系图。构建的图结构再传递给图表示学习模块（如GCN），产生增强的图谱表示。图表示与文本表示共同输入OOD评分模块。与此同时，对于进入深度阶段的疑似OOD样本，探针生成模块会基于图谱表示生成若干探索样本（图中红色虚线表示反馈回流模型训练）。OOD评分模块包括一个条件正态化流模型，利用高斯混合先验对ID数据进行密度学习。它在训练时不仅学习ID样本的最大似然，也通过排斥损失将生成探针判为低概率。最终，该模块输出OOD分数供判别使用。如果样本被判为OOD，则触发解释模块（图中未详细绘出），基于因果图和流模型证据生成解释。每个矩形方框表示一个功能模块，箭头表示数据或梯度流动方向。}
 \label{fig:architecture}
 \end{figure}

图\ref{fig:architecture}所示的架构突出了我们方法的新颖之处：与传统仅依赖编码器+分类器的框架不同，我们增加了一条\textbf{图构建与表示}路径，以及\textbf{生成式探针与流模型}路径。这两条新路径协同作用，使CP-ABR++能够在保持高效性的同时，大幅提升对近OOD的辨识能力和对未知空间的探索能力。在下一节中，我们将详细描述每个模块的输入输出、核心算法和损失函数如何设计，并给出训练与推理流程的伪代码说明。

\subsection{Stage-0：级联能量门}\label{sec:stage0}
 \textbf{输入输出与功能：}Stage-0模块的输入为待检测文本$x$，输出为一个初步判别结果。如果模型对$x$的判别置信度足够高且倾向于某一ID类别，则$x$直接被标记为ID并输出预测类别$\hat{y}$；否则$x$将作为“不确定”样本被传递到后续阶段作进一步处理。该模块的作用相当于一个“快速筛选器”或“门控器”：用极低的计算成本处理大部分易判别样本，仅将疑似OOD或高不确定性样本送入复杂的后续模块，从而优化平均推理效率。

\textbf{模型原理：}我们采用\textbf{能量分数}作为判别不确定性的度量。具体来说，令文本编码器$Enc(\cdot)$提取输入$x$的向量表示$\mathbf{h}=Enc(x)$，并经过分类头$Cls(\cdot)$输出对$C$个已知类别的logits向量$\mathbf{z} = Cls(\mathbf{h})\in \mathbb{R}^C$。能量分数$E(x)$定义为logits经过对数和指数运算得到的负对数值：

\begin{equation}
 E(x) = -\log \sum_{c=1}^{C} \exp(z_c),
 \label{eq:energy}
 \end{equation}

其中$z_c$表示$\mathbf{z}$中对应类别$c$的分量。直观来说，$-\log\sum \exp(z_c)$等价于对数似然的负值，它会将较大的logits（对应某个高概率类别）的影响凸显出来。如果模型对输入$x$属于某一ID类非常有信心，则对应类别的logit将远高于其他类别，导致$\sum \exp(z_c)$近似等于最大logit的指数，此时$E(x)$将取得一个较小值；反之，如果模型输出的logits分布较为平坦（缺乏明确判断），则$E(x)$会偏大。因此，$E(x)$可视作“不属于任何已知类别”的一个分数，值越大表示$x$越可能为OOD。

\textbf{判别机制：}我们预先利用训练集上的ID样本能量分布来确定一个能量阈值$\tau_E$。一种简单而有效的策略是选取使训练集$100%$ ID样本通过率约为$\alpha$（如0.95）的分位数作为$\tau_E$，以在保证大部分ID样本被直接接受的同时，将能量异常高的样本标记为需要进一步检查。具体判别策略为：

- 若 $E(x) < \tau_E$，则判定$x$为ID样本，模型直接输出$\hat{y} = \arg\max_c z_c$作为预测类别，终止后续推理。
- 若 $E(x) \ge \tau_E$，则$x$被标记为“不确定”，进入Stage-1进行深度处理。

在训练过程中，我们对文本编码器和分类头进行常规的监督学习，即最小化ID样本的交叉熵损失$\mathcal{L}*{\text{cls}} = -\frac{1}{N}\sum*{i=1}^N \log \Pr(y_i \mid x_i)$，以确保分类器具备良好的闭集分类性能。此外，我们记录训练集ID样本的能量值分布，用于设定$\tau_E$。需要强调的是，Stage-0本身并不引入额外的参数或复杂计算，仅利用了分类器已有的logits信息，因此几乎不增加推理负担。

\textbf{效率优势：}在推理时，大量明显属于ID的样本（尤其是训练空间覆盖充分的常见意图）会被Stage-0以$O(1)$的计算直接处理完毕，只有少部分难判样本才进入后续GNN、流模型等复杂模块。这种\emph{级联架构}符合统计决策的最优性原则：在保证总体检测性能的同时，将平均计算成本降到最低。我们在实验中将验证，Stage-0的能量门可以滤除约XX%的ID查询，以极小代价提供准确分类，从而显著提升系统的吞吐量。

\subsection{Stage-1：因果语义图构建与表示增强}\label{sec:stage1}
 \textbf{输入输出与总体思路：}Stage-1的输入是通过Stage-0门控的“不确定”样本$x$以及训练数据$\mathcal{D}*{\text{train}}$（及可选的外部知识库）。输出是一个增强的样本表示$\mathbf{h}*{*}$，它融合了$x$与其在训练集及知识库中的相关邻居之间的关系信息。为此，我们为每个输入$x$**构建一个专属的语义关系子图**，其中包含与$x$语义相关的若干训练样本和概念节点，并通过图神经网络提取$x$在此图上的嵌入表示$\mathbf{h}_{*}$。直观来说，这一步的目的在于赋予模型“跨样本的视野”：如果说Stage-0只看到了$x$自身，那么Stage-1则让模型看到$x$与训练过的知识之间的连接与差异，从而更稳健地识别细微的语义偏移。

\textbf{图节点与边的构建：}我们利用大型预训练语言模型LLM（例如GPT-3.5）来指导图的构建。具体而言，对于输入$x$，我们从训练集中选取与$x$最相关的一批样本（如通过嵌入相似度或检索模型获取top-$k$相似句子），初始化图节点集合$V$为${x} \cup \mathcal{N}_k(x)$，其中$\mathcal{N}*k(x)$表示训练集中与$x$语义最接近的$k$个句子。同时，我们可以将这些句子所属的意图类别节点或其中提及的重要实体/概念也纳入图中，以丰富图的节点种类。例如，在意图检测任务中，同一领域的意图往往存在关联，若$x$属于未知意图，可能与某已知领域的多个意图均有部分重叠，我们可引入“领域”节点连接相关意图节点。LLM在此处扮演\emph{“引导者”}角色：我们向LLM提供$x$及$\mathcal{N}\*k(x)$，令其产生关于$x$与这些邻居之间潜在关系的描述，例如“样本$x$与样本$y$在\texttt{[slot: 账户]}上相关”或者“样本$x$涉及到一个训练集中未出现过的新概念Z”。根据LLM的输出，我们为图添加相应的边$e=(u,v)$并赋予权重$w\*{uv}$：若LLM认为两个节点存在强语义/因果关联，则添加高权重边，否则无边或低权重。值得一提的是，LLM生成的知识可能存在\textbf{幻觉}（hallucination），即无根据的关系。为此，我们引入一个\emph{LLM自检机制}：再次调用LLM或一个校验模型，对每条候选边进行事实性验证，只有通过验证的边才能在最终图中保留或被赋予较高权重$w*{uv}$。例如，若LLM最初添加了一条$x$和节点“贷款_申请”之间的边，但自检模型发现“贷款”概念在训练集中从未出现过，则我们将该边标记为不可靠，在图计算时降低其权重影响。

\textbf{异质图表示与GNN聚合：}构建好的关系图$G=(V,E,W)$可能是一个\textbf{异质图}（heterogeneous graph），即包含不同类型的节点（如文本节点和概念节点）和不同类型的关系（如语义相似关系、类别从属关系等）。为在该图上学习节点表示，我们采用异质图神经网络进行消息传递和聚合。在实现上，我们将每个节点初始化为一个向量表示$\mathbf{h}^{(0)}_v$：对于文本节点，使用其编码器表示（如$Enc(x)$或$Enc(y)$）；对于概念节点，可以使用预训练词向量或通过定义一个可学习嵌入向量。我们使用异质GraphSAGE或关系图卷积等方法，在$l$层迭代中更新节点表示：

\begin{equation}
 \mathbf{h}*v^{(l+1)} = \sigma\Big( W_0^{(l)} \mathbf{h}\*v^{(l)} + \sum\*{r\in\mathcal{R}}\sum*{u \in \mathcal{N}_r(v)} \frac{1}{|\mathcal{N}_r(v)|} W_r^{(l)} \mathbf{h}_u^{(l)} \Big),
 \label{eq:het-gcn}
 \end{equation}

其中$\mathcal{R}$表示关系类型集合，$\mathcal{N}*r(v)$表示节点$v$在关系类型$r$下的邻居集合，$W_r^{(l)}$为对应关系类型的线性变换矩阵，$\sigma$是非线性激活函数（如ReLU）。上述公式对不同类型的邻居分别线性变换并平均聚合，再与节点自身的信息组合，实现针对异质关系的消息传递。在我们的场景中，主要的关系类型包括“语义近邻”（文本-文本之间）、“同属意图类”（文本-意图类之间）、“实体关联”（文本-概念之间）等。经过$L$层传播后，我们取节点$x$的最终表示$\mathbf{h}*{*} = \mathbf{h}\*x^{(L)}$作为Stage-1的输出。这个$\mathbf{h}\*{*}$融合了$x$在图中邻居的情报，可视为$x$的一种\textbf{结构增强表示}：若$x$确为ID样本，它将在图中与某些ID节点形成紧密社区，$\mathbf{h}*{\*}$将与标准表示$\mathbf{h}$相差不大；但若$x$为OOD样本，可能出现两种情况：（i）$x$连接到多个类别但都较弱，导致$\mathbf{h}*{*}$的范数或集中性显著下降，（ii）$x$连接引入了图中新的孤立概念节点，使$\mathbf{h}_{*}$偏向该新概念的方向。无论哪种情况，$\mathbf{h}_{*}$都将提供额外的信息，有助于后续模块更好地区分ID/OOD。

\textbf{损失设计：}由于Stage-1的图构建和GNN传播主要是无监督过程，我们没有针对$\mathbf{h}*{\*}$设计额外的监督信号，其训练主要依赖Stage-3的整体目标来间接优化。然而，我们需注意图的可靠性对最终性能的影响。为此，我们在训练数据上进行了一些预训练步骤：例如，对训练集本身构建全局语义图并对其进行图表示学习，以确保GNN能够正确地聚合同类样本、区分异类样本。这相当于通过已知ID数据对GNN进行\textbf{有监督预训练}：我们最小化一个分类损失$\mathcal{L}*{\text{graph}}$，要求利用图上一个ID样本的邻域表示来预测其意图类别。这样训练过的GNN在遇到新样本时，更能将其与正确的类别邻域对齐，从而提高$\mathbf{h}_{*}$的判别力。

\textbf{小结：}Stage-1赋予模型一种“类内记忆”的能力——通过图谱在语义空间中找到“和我相似的过去案例”。这在细粒度场景下非常关键。例如，句子“我的借记卡不能用了”若未在训练中出现，单靠它本身模型可能犹豫于分类为“卡被冻结”还是“卡未激活”。但通过图谱发现其与训练样本“信用卡无法使用”有联系且该样本属于“卡未激活”意图，则模型倾向于认为它属于已知类而非OOD。而若某输入与任何训练意图都只有极弱的联系（如出现了训练集中未出现过的金融术语），图表示会将其推向图结构的边缘地带，从而提示后续模块将其视为候选OOD。正是这种通过因果图获取上下文的机制，使我们的模型在近OOD判别上胜过传统只看孤立句子的模型。后续Stage-3的结果也将证明，这种显式的图谱结构对降低误判率有显著作用。

\subsection{Stage-2：多样性感知的自适应探针生成}\label{sec:stage2}
 \textbf{输入输出与动机：}Stage-2模块输入当前样本的增强表示$\mathbf{h}*{\*}$以及模型当前的判别状态，输出一组针对模型的“探针”样本集合${x*{\text{probe}}}$。这些探针样本并非真实用户输入，而是我们使用生成模型模拟出的“假样本”，目的是\textbf{主动暴露模型的弱点并加以弥补}。传统模型只能被动地等待真实OOD样本在测试时出现，而本模块通过生成接近决策边界的合成样本，在训练阶段就对模型进行针对性强化，从而提升其对未知分布的泛化能力。可以将其类比为安全测试中的渗透攻击：我们通过探针有意识地攻击模型，让模型在“受控”的环境下经历失败，再据此调整自身，以避免未来在真实环境中出现类似失误。

\textbf{探针生成概述：}探针样本需要满足两个要求：（i）能够对当前模型构成挑战，即尽可能让模型误判；（ii）在语义上保持多样性和合理性，即覆盖尽可能广的未知空间而不过于离谱或重复。为此，我们训练一个\textbf{条件生成模型}$Gen$，以$\mathbf{h}*{\*}$作为条件输入来生成文本样本。具体实现时，可选用条件扩散模型或生成对抗网络（GAN）等。在我们的设计中，$\mathbf{h}*{*}$扮演“语义引导”的角色：$Gen$尝试生成与$\mathbf{h}_{*}$语义相关但稍有偏移的新句子。这类句子很可能落在当前模型的边界附近——因为$\mathbf{h}*{\*}$本身是模型对$x$的语义理解，如$x$是未知意图，其$\mathbf{h}*{*}$也带着未识别的成分，因此以$\mathbf{h}_{*}$为种子略作变化就可能得到“似是而非”的样本。

\textbf{对抗性与多样性损失：}我们为探针生成设计了专门的损失函数来平衡攻击性和多样性。生成模型的训练目标是最大化如下目标函数：

\begin{equation}
 \mathcal{L}*{\text{probe}} = \mathcal{L}*{\text{adv}} - \eta ,\mathcal{L}_{\text{div}},
 \label{eq:probe-loss}
 \end{equation}

其中$\mathcal{L}*{\text{adv}}$为对抗性损失，$\mathcal{L}*{\text{div}}$为多样性损失，$\eta$为权衡系数。$\mathcal{L}*{\text{adv}}$鼓励$Gen$生成当前模型容易混淆的样本：具体来说，我们期望生成样本$x*{\text{probe}}$在判别模型眼中看起来像ID，从而造成误分类或低异常分数。这可以通过最大化这些样本的“被判为ID”的概率来实现。例如，若我们将Stage-3输出的异常分数$s(x)$经Sigmoid归一化为属于OOD的概率$\sigma(s(x))$，则$\big(1-\sigma(s(x_{\text{probe}}))\big)$代表模型将$x_{\text{probe}}$当作ID的置信度。我们令生成器尝试\textbf{最大化}$1-\sigma(s(x_{\text{probe}}))$，即最小化

\begin{equation}
 \mathcal{L}*{\text{adv}} = -\mathbb{E}*{x_{\text{probe}} \sim Gen(\mathbf{h}*{\*})}\Big[\log\big(1-\sigma(s(x*{\text{probe}}))\big)\Big],
 \label{eq:adv-loss}
 \end{equation}

这样生成器会不断产生让当前模型判别失误的样本。另一方面，$\mathcal{L}_{\text{div}}$则要求生成的探针样本尽可能多样，而非模式塌陷在几种固定形式上。我们通过增大生成样本在语义空间或词分布上的覆盖度来量化多样性。例如，可以用生成样本集合两两之间的平均余弦距离作为多样性指标，或引入判别器来检测并惩罚重复模式。这里我们采用一种简单有效的实现：对一次生成的$m$个探针样本，计算它们在文本嵌入空间中的总体方差$D$，并定义

\begin{equation}
 \mathcal{L}*{\text{div}} = - D\big({Enc(x*{\text{probe}}^{(1)}), \ldots, Enc(x_{\text{probe}}^{(m)})}\big),
 \end{equation}

即鼓励生成的探针在编码器空间里分散开来。通过最大化$\mathcal{L}*{\text{div}}$，我们避免生成模型反复输出相似的句子，从而探索更广泛的潜在OOD区域。损失函数\eqref{eq:probe-loss}综合了上述两方面：$\mathcal{L}*{\text{adv}}$确保探针有“难度”，$\mathcal{L}_{\text{div}}$确保探针“多样”，两者共同指导生成模型不断优化。

\textbf{自适应生成策略：}探针生成不是“一劳永逸”的——随着判别模型的训练进行，其决策边界会改变。因此，我们采取\textbf{交替训练}的方式，使生成器与判别器（分类器+流模型）彼此博弈、共同进化。在每个训练迭代中，我们执行以下步骤：

1. 固定当前判别模型，更新生成模型$Gen$以最小化$\mathcal{L}_{\text{probe}}$。此时，$Gen$尽力找到现有模型的漏洞。
2. 固定更新后的$Gen$，利用生成的探针样本来更新判别模型。具体做法是在Stage-3的训练中将探针样本视作“拟OOD”样本，应用相应的损失使模型将其判为OOD（见下一节$\mathcal{L}_{\text{repel}}$）。这样，模型逐步修补了先前被$Gen$发现的漏洞。

通过上述交替过程，$Gen$和模型形成类似于生成对抗网络（GAN）的关系：$Gen$不断提出新的挑战，模型不断学习应对。这种\textbf{自适应探针}机制能够避免模型局限于训练集分布，在更广阔的潜在输入空间上获得良好的决策边界。特别地，我们发现在近OOD场景下效果显著：由于近OOD样本与ID样本仅有细微差别，纯判别模型往往对此模糊不清，而生成器可以专门合成这类“边界样本”来强化训练，从而显著减少模型将近OOD错判为ID的概率。在实验部分，我们将通过消融对比来量化探针生成模块对性能的提升幅度。

需要指出的是，Stage-2生成的探针样本\textbf{仅用于训练}，在推理时并不实际生成额外样本，因此不会影响推理效率。它的作用体现在模型参数的优化上，使模型具备更强的开放集识别能力。这也是我们称之为“主动开放集学习”的关键：模型不等待环境赐予更多样本，而是主动想象出可能出现的未见情形进行模拟演练。这一思路在计算机视觉等领域开始受到关注；本章工作则将其创新地引入到文本领域的OOD检测中。

\subsection{Stage-3：基于条件流模型的可靠检测}\label{sec:stage3}
 \textbf{输入输出与判别流程：}Stage-3是CP-ABR++的核心检测模块。它接收来自文本编码器的原始表示$\mathbf{h}$、来自Stage-1的图谱增强表示$\mathbf{h}_{*}$，以及Stage-2可能生成的一批探针样本。输出为最终的OOD判别结果——包括输入样本的异常分数$s(x)$以及判定标签（ID或OOD）。在Stage-3，我们引入\textbf{生成式概率建模}思想，通过学习训练数据（ID样本）的概率分布来进行OOD检测：直观上，若一个样本在训练分布上具有很低的生成概率，则应被视为OOD。我们选择**正态化流模型**作为生成式基础，并通过条件机制和多模态先验改进其性能，使之能够可靠地区分复杂OOD情形。

\textbf{条件正态化流：}标准的正态化流（Normalizing Flow）是一种可逆变换模型$f: \mathcal{X} \leftrightarrow \mathcal{Z}$，通过一系列可微双射将输入$x$映射到一个隐空间向量$z=f(x)$，并依据变换公式计算出数据密度$p_X(x)$。为了利用Stage-1的图信息，我们采用\textbf{条件流}（Conditional Flow），即变换$f$不仅对$x$建模，还接受一个条件向量$\mathbf{c}$作为额外输入共同决定映射。具体到我们模型，$\mathbf{c}$可以取为Stage-1得到的$\mathbf{h}*{\*}$，即将因果图谱编码的信息注入流模型，以调整生成概率的评估。例如，ID样本通常能够在训练图谱中找到紧密邻居，$\mathbf{h}*{*}$对此进行编码，条件流据此会对这些样本给出较高的似然；反之，OOD样本的$\mathbf{h}_{*}$往往“游离”于训练图谱，条件流据此压低其似然值，实现比无条件流更精细的判别。

形式上，我们通过求解变换$f(x; \mathbf{c}) = z$的Jacobian行列式来计算密度：

\begin{equation}
 p_X(x \mid \mathbf{c}) = p_Z(z),\Big|\det \frac{\partial f(x; \mathbf{c})}{\partial x}\Big|^{-1},
 \end{equation}

其中$p_Z(z)$是我们预先设定的隐空间先验分布。与传统流不同，我们的$f$在每一层耦合变换中都会利用$\mathbf{c}$：例如，在基于RealNVP的实现中，$x$被分为两部分$x_{1:d}$和$x_{d+1:D}$，通过层函数

y1:d=x1:d,yd+1:D=xd+1:D⊙exp⁡(s(x1:d,c))+t(x1:d,c),y_{1:d} = x_{1:d}, \quad  y_{d+1:D} = x_{d+1:D} \odot \exp(s(x_{1:d}, \mathbf{c})) + t(x_{1:d}, \mathbf{c}),

来引入条件$\mathbf{c}$（其中$s(\cdot), t(\cdot)$为可学习的仿射变换参数，由$x_{1:d}$和$\mathbf{c}$共同决定）。这样，条件信息在每步变换中调节尺度和平移，从而影响最终密度估计。

\textbf{多模态先验：}先验$p_Z(z)$的选择对流模型性能有重要影响。经典流模型多假定$z$服从标准多元正态分布，但在实际数据中，ID分布可能是多峰的。例如，在CLINC150数据集中，不同领域的意图可能分别对应特征空间的若干簇，每个簇可视为一个高斯成分。本章采用式\eqref{eq:gmm-prior}所示的高斯混合模型（GMM）作为先验，以提高对复杂分布的拟合能力。GMM的参数$(\pi_k, \mu_k, \Sigma_k)$可以通过对训练集表示在隐空间中的聚类估计得到，也可以作为可学习参数在训练中不断优化。相比单一高斯，混合先验能够显著降低流模型在OOD检测中的\textbf{密度陷阱}问题：过去研究发现，某些OOD样本（尤其是远OOD）可能在单峰流模型下得到比ID样本更高的似然（称为“奇异解”），而多模态先验通过赋予隐空间更复杂的形状，避免将过多概率质量集中在单一点上，从而缓解此问题。我们的实验证据也将展示，多模态先验能使检测错误率明显下降。

\textbf{训练目标与损失：}Stage-3涉及判别模型的主要训练过程。我们定义以下几项损失：

- \textbf{最大似然损失 $\mathcal{L}_{\text{flow}}$}：提高ID样本在流模型下的概率，即最小化负对数似然：

\begin{equation}
 \mathcal{L}*{\text{flow}} = -\mathbb{E}*{x \in \mathcal{D}*{train}} \log p_X(x \mid \mathbf{h}*{*}(x)).
 \label{eq:flow-loss}
 \end{equation}

通过最小化$\mathcal{L}*{\text{flow}}$，模型学习到将训练集样本映射到先验高密度区域，同时利用$\mathbf{h}*{*}$提供的条件信息校正分布形状。

- \textbf{探针排斥损失 $\mathcal{L}*{\text{repel}}$}：降低生成探针样本在流模型下的概率密度，促使模型将这些$Gen$产生的“难样本”视为OOD。我们采用与\eqref{eq:adv-loss}类似但作用相反的策略：最小化$\log(1-\sigma(s(x*{\text{probe}})))$的负值等价于最大化$\sigma(s(x_{\text{probe}}))$，即提升模型判定探针为OOD的置信度。因此定义：

\begin{equation}
 \mathcal{L}*{\text{repel}} = -\lambda,\mathbb{E}*{x_{\text{probe}} \sim Gen}\Big[\log \sigma\big(s(x_{\text{probe}})\big)\Big] = -\lambda,\mathbb{E}*{x*{\text{probe}} \sim Gen}\Big[\log\big(1 - (1-\sigma(s(x_{\text{probe}})))\big)\Big],
 \label{eq:repel-loss}
 \end{equation}

其中$\lambda$为权重超参数。$\mathcal{L}_{\text{repel}}$直观解释为：让流模型减少对探针样本赋予的概率，等价于在隐空间中把这些样本“推离”训练数据簇的位置。通过此损失，模型针对生成器找到的每个漏洞及时调整自己，将探针逐出高密度区。

- \textbf{分类损失 $\mathcal{L}*{\text{cls}}$}：为确保ID样本的类别判别能力，我们仍包含传统的交叉熵损失$\mathcal{L}*{\text{cls}}$用于训练文本编码器和分类头（与Stage-0相同）。虽然Stage-3的流模型可以独立进行OOD判定，但最终系统还需要给出ID样本所属类别，因此保持分类器性能不降低也很重要。另外，分类器提供的判别信息也可融合进最终OOD分数，从另一角度提升检测准确率。

综合以上，我们的判别模型训练目标为最小化：

\begin{equation}
 \mathcal{L}*{\text{stage3}} = \mathcal{L}*{\text{cls}} + \mathcal{L}*{\text{flow}} + \mathcal{L}*{\text{repel}}.
 \end{equation}

在实际训练中，$\mathcal{L}*{\text{cls}}$和$\mathcal{L}*{\text{flow}}$通常通过对ID数据的一个mini-batch计算，$\mathcal{L}*{\text{repel}}$则通过Stage-2生成的探针样本计算，我们采用上节提到的交替更新策略分别优化生成器和判别器。值得注意的是，$\mathcal{L}*{\text{repel}}$仅在生成器开始产生有效探针后才有作用，训练初期生成器较弱时该项影响有限；而随着生成器增强，$\mathcal{L}_{\text{repel}}$确保判别模型同步提升，二者此消彼长，共同进化。

\textbf{推理与决策：}在完成训练后，CP-ABR++的推理过程如下：给定一个新输入$x_{\text{test}}$，依次通过Stage-0计算能量$E(x_{\text{test}})$并门控；若通过则经Stage-1构建图并计算$\mathbf{h}*{\*}$，随后Stage-3的流模型计算$p_X(x*{\text{test}} \mid \mathbf{h}*{\*})$并得出异常分数$s(x*{\text{test}})=-\log p_X$。结合分类器输出，我们得到最终的判别：如果$s(x_{\text{test}})>\tau_s$（阈值由验证集确定），则判定为OOD，否则判为ID且预测类别为$y=\arg\max_c z_c$（Stage-0分类器给出的类别）。在我们的实现中，我们还利用能量$E(x)$作为辅助分数，与$s(x)$加权平均构成最终的综合分数$score(x)=\alpha\cdot s(x) + (1-\alpha)\cdot \widetilde{E}(x)$（$\widetilde{E}(x)$为归一化到相似量级的能量分数），以取得更稳健的结果。这种多源信息融合在文献中也被证明可以提升检测性能。最终，Stage-3以高可靠性完成了对$ x_{\text{test}}$的ID/OOD判别，并将结果传递给Stage-4进行可能的解释生成。

\subsection{Stage-4：基于证据链的忠实解释}\label{sec:stage4}
 \textbf{输入输出与必要性：}Stage-4的输入是被判为OOD的样本$x_{\text{OOD}}$，以及模型在Stage-1和Stage-3中得到的中间信息（如因果图关系、流模型密度分布等）；输出是一段针对该输入的结构化自然语言解释文本。随着OOD检测模型部署于安全关键的应用（如医疗问答系统），仅给出“OOD”判定往往不足以令用户或管理员信服。Stage-4旨在为每一次OOD判定提供\textbf{可检查的理由}，提升模型决策的透明度和可信度。与传统的注意力热图或示例回溯解释不同，我们的方法生成包含明确语义证据的解释链，直接指明模型认为输入超出训练分布的具体原因。

\textbf{证据A：因果图谱线索}。我们首先从Stage-1构建的语义图中提取解释证据。一般来说，若一个输入被判为OOD，往往在语义图中会出现某种“断裂”现象：例如，该输入节点与训练集其他节点仅存在非常微弱的连接，或者其连接涉及的关键概念在ID数据中从未出现过。为定量描述这种现象，我们可以计算输入节点与图中$k$近邻节点的平均边权重，或统计输入引入的新概念节点的数量。如果平均边权重远低于ID样本的典型值，或者新概念节点数量显著>0，则这些都是OOD的强烈指示。我们定义\textbf{图异常分数}$\Delta_{\text{graph}}(x)$，例如为输入节点度数的倒数乘以新概念节点个数的函数。当$\Delta_{\text{graph}}(x)$高于某一阈值时，即可认为存在“关系断裂”。作为证据A，我们提取那些与输入$x$相关但在训练图谱中无支撑的概念或关系。例如，对于输入“我想查询一下车贷的余额”，训练集中从未出现过“车贷”概念，我们将此标记为证据A1：“概念‘车贷’未在训练语料中出现”。再如若输入涉及多个领域混杂（跨领域组合句），其在图中连接到不同领域节点但均很弱，我们提取此模式作为证据A2：“该请求同时涉及多个训练未见的跨领域组合（XX和YY），与已知意图的关联不明确”。

\textbf{证据B：生成模型线索}。其次，我们从Stage-3的流模型获得另一种证据。流模型通过估计似然识别OOD，其判定基础可以从隐空间投影中看出。我们可以计算输入$x$对应的隐向量$z=f(x; \mathbf{h}*{\*})$与各高斯先验中心$\mu_k$之间的马氏距离$M_k = (z-\mu_k)^\mathsf{T}\Sigma_k^{-1}(z-\mu_k)$，并找出最小的$M*{\min}$和对应的分量$k^*$。对于ID样本，$M_{\min}$应在某一范围内（取决于先验协方差），而若$M_{\min}$远大于训练样本在该分量下的典型值，则意味着$x$甚至对最接近的ID簇而言也是异常的。我们将此作为证据B：例如，“该输入在训练分布的投影密度仅为$1.2\times 10^{-9}$，显著低于正常范围”。或者描述为“该输入投射到潜在空间后与最近的已知类别簇中心距离很远”，这是较通俗的表述。除了密度值外，我们还可以结合Stage-2的信息：若在训练时生成器曾合成类似$x$的探针并被模型学会拒绝，这意味着$x$恰好落入模型刻意学习的“拒绝域”。我们可以将探针样本片段作为例子包含在解释中，例如“模型曾训练识别类似‘查询贷款余额’的异常请求，因此判断当前输入属于此异常类型”。这种证据非常直接地展示了模型判定并非武断，而是基于已学到的规则。

\textbf{解释生成：}一旦获得证据A和B，我们按照预先设计的模板构造解释文本的骨架。模板包括：引言句，列出主要异常点，以及结论句。一个简化的模板示例如下：

```
请求 "*用户请求*" 被识别为 **分布外**。主要原因：*(1)* 该请求包含了训练集中未出现过的概念 "车贷"，在语义图谱中无相关连接；*(2)* 基于概率模型计算，其出现概率极低（密度值仅为训练平均的$10^{-5}$倍)。因此，模型判断该请求不属于已知的用户意图类别。 
```

我们将上述模板及插入的证据片段提交给LLM（如GPT-4）进行润色完善，使其成为流畅、专业的说明。LLM会确保语句通顺并可能补充一些背景短语，例如“具体来说”、“此外”等，使解释读起来更自然。但需注意，我们要求LLM严格遵循事实证据，不引入任何模型未提供的信息，以确保**忠实性**。最终生成的解释包含了两个层面的原因：语义层面的（概念/关系缺失）和统计层面的（概率异常），形成一个证据链。相较于传统的注意力可视化等方法，我们的解释更加明确具体，直接指出了模型判定的依据所在。这种清晰的可解释性对实际部署尤为重要：运维人员可根据解释判断模型错误的成因（如某新领域未覆盖），用户也可理解为什么系统无法处理他们的请求（如涉及未知业务）。

\textbf{示例：}假设输入$x_{\text{OOD}}$为一句近OOD查询：“我忘记了信用卡的网银登录密码怎么办？” 模型通过CP-ABR++判定其为OOD。解释模块可能生成如下文本：

“模型将该请求识别为分布外（OOD）。首先，该请求涉及概念‘网银登录密码’，而训练语料中没有相关话题，模型在语义图中找不到与之相连的已知意图（证据A）。其次，模型基于学习到的概率模型计算出该请求属于训练分布的概率极低（约为正常请求的$10^{-6}$，证据B），明显偏离了已知用户请求模式。因此，系统判断它不属于目前支持的任何已知意图。”

这种解释一方面指出了具体未知的概念使模型无法匹配，另一方面给出了模型置信度极低的量化依据，因而具有很强的说服力。我们在实验中也将对若干案例进行展示，评估解释的准确性和可理解性。

\subsection{训练与推理算法伪代码}\label{sec:algorithm}
 为了总结CP-ABR++模型各阶段的协同工作流程，我们给出训练阶段的算法伪代码（算法\ref{alg:training}），展示各模块交替优化的过程。算法中包含了Stage-0到Stage-3的主要计算步骤和损失计算，以及Stage-4所需的信息提取部分。需要说明的是，推理阶段的大部分模块权重固定、按序执行，逻辑相对简单，受篇幅所限这里不再赘述。

\begin{algorithm}[t]
 \caption{CP-ABR++ 模型训练算法}
 \label{alg:training}
 \small
 \begin{algorithmic}[1]
 \Require 训练集$\mathcal{D}*{train}={(x_i,y_i)}*{i=1}^N$（仅ID样本），预训练语言模型$LM$用于图构建与自检，初始化文本编码器$Enc$、分类器$Cls$、图神经网络$GNN$、条件流模型$Flow$、探针生成器$Gen$的参数。
 \State 使用$\mathcal{D}*{train}$预训练分类器：最小化交叉熵损失$\mathcal{L}*{cls}$训练$Enc+Cls$，并记录每个$x_i$的能量分数$E(x_i)$（公式\eqref{eq:energy}），统计能量分布确定阈值$\tau_E$。
 \State 可选：构建训练集全局语义图并预训练$GNN$（使其能正确聚合同类样本）。
 \For{each epoch = 1 to $N_{epoch}$}
 \For{each mini-batch $B = {(x_j, y_j)}*{j=1}^B$}
 \State // \emph{Stage-0: 能量门筛选与分类训练}
 \For{each $(x_j,y_j) \in B$}
 \State 计算$\mathbf{h}\*j = Enc(x_j)$，$\mathbf{z}\*j = Cls(\mathbf{h}\*j)$，$\hat{y}\*j = \arg\max \mathbf{z}\*j$，
 \State 计算能量$E(x_j)$（公式\eqref{eq:energy}）；计算分类损失累加$\mathcal{L}\*{cls} \mathrel{+}= -\log \Pr(y_j \mid x_j)$。
 \If{$E(x_j) < \tau_E$}
 \State 样本$j$判为易分类ID，跳过Stage-1/2，直接用于更新分类器和流模型的ID训练。
 \Else
 \State 样本$j$标记为疑似OOD，进入Stage-1/2/3处理。
 \EndIf
 \EndFor
 \State // \emph{Stage-1: 图构建与表征增强}
 \For{each 被标记疑似OOD的 $x_j$}
 \State 基于$LM$和$\mathcal{D}\*{train}$构建$x_j$的语义关系图$G_j=(V_j,E_j,W_j)$，移除幻觉边。
 \State 将$x_j$插入图中，初始表示$\mathbf{h}^{(0)}\*{x_j}=\mathbf{h}\*j$。对图$G_j$运行$L$层$GNN$消息传递，得$\mathbf{h}\*{j\*} = \mathbf{h}^{(L)}\*{x_j}$（公式\eqref{eq:het-gcn}）。
 \EndFor
 \State // \emph{Stage-2: 探针样本生成}
 \State 使用当前$Gen$，对每个疑似OOD样本的$\mathbf{h}\*{j\*}$生成$m$个探针${x*{\text{probe},j,k}}*{k=1}^m$。
 \State 计算生成器损失$\mathcal{L}*{adv}$和$\mathcal{L}*{div}$（公式\eqref{eq:adv-loss}等），得到$\mathcal{L}*{probe}$（公式\eqref{eq:probe-loss}）。
 \State 暂停判别器参数，更新生成器$Gen$参数：$\theta_{Gen} \leftarrow \theta_{Gen} - \gamma \nabla_{\theta_{Gen}} \mathcal{L}*{probe}$。
 \State // \emph{Stage-3: 条件流模型训练}
 \State 对mini-batch所有ID样本（包括易分类ID和疑似OOD中的ID）集合$\mathcal{B}*{ID}$，计算流模型负对数似然损失：$\mathcal{L}*{flow} \mathrel{+}= -\sum*{x_j \in \mathcal{B}*{ID}} \log p_X(x_j \mid \mathbf{h}*{j*})$（公式\eqref{eq:flow-loss}）。
 \State 对所有生成的探针样本集合$\mathcal{B}*{probe} = \cup_j {x*{\text{probe},j,k}}$，计算$\mathcal{L}*{repel} \mathrel{+}= -\sum*{x \in \mathcal{B}*{probe}} \log \sigma(s(x))$（公式\eqref{eq:repel-loss}）。
 \State 合计判别器损失：$\mathcal{L}*{disc} = \mathcal{L}*{cls} + \mathcal{L}*{flow} + \mathcal{L}*{repel}$。
 \State 暂停生成器参数，更新判别器（$Enc, Cls, GNN, Flow$）参数：$\theta \leftarrow \theta - \gamma' \nabla*{\theta} \mathcal{L}_{disc}$。
 \EndFor
 \State （可选）使用验证集调整$\tau_E$和最終判别阈值$\tau_s$。
 \EndFor
 \State \textbf{return} 训练好的$Enc, Cls, GNN, Flow, Gen$（推理时一般不需调用$Gen$）。
 \end{algorithmic}
 \end{algorithm}

算法\ref{alg:training}描述了模型的训练过程。最终，我们得到一个端到端的CP-ABR++模型：推理时，对于普通ID查询，Stage-0迅速响应并给出结果；对于疑似OOD查询，模型自动经历图谱增强和概率判别，以更高代价换取更精准的判断；对于判出的OOD结果，模型还能给出证据充分的解释。这种按需分配计算资源的级联机制，使我们在保证鲁棒性的同时，没有牺牲效率。下一节我们将通过实验评估全面验证本章所提方法的有效性。

\section{实验评估}\label{sec:experiment}

本节我们通过大量实验从各方面评估CP-ABR++模型的性能。首先介绍实验设置，包括数据集、评价指标、对比基线和实现细节；然后汇报主实验结果，并分析我们的方法相较基线的改进情况；接着进行消融实验和超参数敏感性分析，以验证各模块的作用和模型的稳健性；最后给出案例研究与可视化，加深对模型工作机制的理解。

\subsection{实验设置}\label{sec:exp-setup}

\subsubsection{数据集}\label{sec:datasets}
 我们选取了当前文本OOD检测领域中具有代表性的多个公开数据集，涵盖不同场景和难度，以全面测试模型的表现：

- \textbf{CLINC150}：一个多领域的意图识别数据集，被广泛视为文本OOD检测的事实标准之一。它包含10个领域下共150个用户意图（每个领域15个意图），以及一个专门的\textbf{Out-of-Scope (OOS)}类别用于OOD样本。每个ID意图有100条训练样本，数据均衡，总训练样本15,000条。测试集包含每个意图的样本以及1000条左右的OOS样本。CLINC150的设计使其同时考察\textbf{近OOD}（已知领域的新意图）和\textbf{远OOD}（完全未知领域）检测能力：ID类别分布广且细，OOD样本来自10个领域之外的开放话语。这一数据集在众多OOD检测论文中被采用。本实验使用Larson等人提供的官方划分：15k训练，3.1k验证，5.5k测试，OOD样本在验证集和测试集中均标注为“OOS”。需要注意数据版本问题：我们采用原始发布的JSON版本并自行划分训练/验证/测试，以确保结果可复现。
- \textbf{Banking77}：一个单领域（银行客服）但意图类别数量众多且细粒度的数据集，常用于检验模型在高细粒度场景下的区分能力。该数据集包含13,083条实际银行用户客服查询，覆盖77种具体意图（例如“账户余额查询”、“信用卡激活”、“忘记PIN码”等）。所有句子都属于银行业务这一单一大领域，因而语义相互相关度较高。原数据集不提供OOD划分，我们遵循文献中的常用方案进行\textbf{意图留出}评估：即在77个意图中随机选取若干个作为“未见”OOD类别，其余作为训练时的ID类别。模型在这些ID类别上训练，但测试时需要识别被留出的意图为OOD。我们选择留出15个意图（约20%）作为OOD，通过多次独立试验验证这样的划分具有代表性和挑战性：被留出的意图往往与训练意图在措辞和主题上高度相似（均属银行领域），属于典型的近OOD。我们报告在3种不同留出划分下模型性能的平均值，以减少偶然性偏差。Banking77数据的一个显著特点是**类内含义极其接近**，这对OOD检测提出了更苛刻的要求：例如，“card_not_working”（卡不能用）和“card_swallowed”（卡被ATM吞了）是两个不同意图，但表面表达非常类似。即使对于人类，在不知道细则的情况下也较难区分这类细微差异。这意味着一个模型若能在Banking77的留出任务上取得好成绩，证明其确实捕捉到了深入的语义细节，而不仅仅是依赖关键词。该数据集由Casanueva等人发布，在few-shot学习和意图检测研究中被频繁使用，也是MTEB基准的一部分。目前微调的RoBERTa分类器在满监督下可达约93.5%的封闭集准确率。我们的任务比封闭分类更难，因为模型需同时保证已知意图分类准确，还要识别出15个未知意图。数据划分上，我们将原数据集按照作者建议的方式随机分成训练（约10000条）、验证（1000+条）和测试（around 3000条），保证各意图在不同划分中分布一致。在模型训练时，移除的OOD意图样本全部用于测试，仅ID部分用于训练。
- \textbf{ROSTD (Real OOD SM data)}：这是一个专门用于OOD检测的测试集，带有真实且具有迷惑性的OOD样本，由Gangal等人在2019年构建。ROSTD基于一个实际的任务型对话数据集（包括3个大类：闹钟、提醒和天气，每类下4个细化意图）。原训练集有约30,000条ID语句，作者另外动员人工编写了4,500条不属于任何已知意图的OOD语句。这些OOD语句并非随意生成，而是**基于人对系统可能未涵盖内容的猜测**，具有相当的迷惑性和真实性。例如，对于闹钟/提醒类的系统，人工编写的OOD样本可能是“告诉我股市开盘时间”（表面像提醒事项，但超出系统功能）。ROSTD的重要意义在于：很多在简单合成OOD上表现良好的模型，在ROSTD上性能会大幅下降。因此，它被视为OOD检测模型鲁棒性的一块“试金石”。在我们的实验中，我们不会将ROSTD用于训练，而是仅作为**最终测试集**来评估模型在完全未知场景下的泛化性能。具体做法是：先在CLINC150和Banking77上训练和调优模型，然后直接在ROSTD的测试集中测评性能。我们报告模型在ROSTD上的AUROC等指标，以验证其在真实OOD场景下的有效性。需要说明的是，我们并未对原始ROSTD数据进行任何微调，这确保了测试的严格性。ROSTD数据由原作者提供，其OOD部分（约4500条）与ID部分大小相当且语义相近度高，使得此测试极具挑战。
- \textbf{ToxiGen}：一个由LLM生成的大规模对抗性文本数据集，含有隐蔽的有害内容，用于测试模型的安全性鲁棒性。ToxiGen由Hartvigsen等人提出。他们利用GPT-3通过人机对抗迭代算法（称为ALICE）生成了274k条涉及13个人群的陈述，每条被标注为“有毒”或“良性”。有毒语句经过设计往往非常隐晦，表面看似中性甚至正面，但隐含冒犯和歧视，例如：“我听说过一些关于XX群体勤劳守法的故事，但显然那只是故事”。这些微妙的攻击性内容常常能骗过传统的有害内容检测器。我们将ToxiGen引入，是为了评估OOD检测模型在极端“远OOD”场景下的表现：训练集（如CLINC150或Banking77）通常不包含仇恨言论，这意味着任何带有仇恨/offensive倾向的输入都属于分布外。然而普通模型可能由于措辞较礼貌而无法察觉这些输入的异常性。我们期望CP-ABR++借助图谱常识（例如侦测到语义上的不协调）和生成式判别（极低似然），能够较好地区分此类有害输入。在实验中，我们从ToxiGen中随机采样了一定数量的“隐式有毒”语句和对应的“良性”语句，将它们作为额外的测试集供模型判别。如果模型足够敏锐，应该倾向于将这些有毒语句判为OOD（因为训练集中无类似攻击性内容），而将良性语句可能视作ID或无害。我们将通过检测准确率和召回等指标报告模型在该集合上的性能，以探讨CP-ABR++在AI安全方向的潜力。需要强调，我们并未用ToxiGen来训练或调参，以免引入偏见，仅作为附加测评使用。

上述数据集基本涵盖了文本OOD检测任务的主要应用场景：CLINC150代表多领域广覆盖的数字助理，Banking77代表单领域细粒度客服，ROSTD模拟实际系统的出圈请求，ToxiGen测试模型对恶意输入的识别。数据统计信息和任务设置总结如表\ref{tab:datasets}所示。

\begin{table}[t]
 \centering
 \caption{实验中使用的数据集概览及任务设置。ID类别数和样本数指训练集（仅ID）；OOD类型指出OOD样本相对于ID的关系；OOD样本仅用于测试（除CLINC150外自带OOD划分）。}
 \label{tab:datasets}
 \begin{tabular}{lcccc}
 \toprule
 \textbf{数据集} & \textbf{ID类别数} & \textbf{ID训练样本} & \textbf{OOD类型} & \textbf{OOD测试样本}\
 \midrule
 CLINC150 & 150 (10域) & 15,000 & 原生OOD (近+远) & 1,000\
 Banking77 & 77 (1域) & $\sim$10,000 & 留出意图 (近) & $\sim$2,600\
 ROSTD & 12 (3类) & 30,000 & 人工策划 (难近) & 4,500\
 ToxiGen & N/A & N/A & 对抗生成 (远) & 1,000 (抽样)\
 \bottomrule
 \end{tabular}
 \end{table}

\subsubsection{评价指标}\label{sec:metrics}
 我们采用OOD检测任务中的通用评价指标来衡量模型性能，包括：

- \textbf{AUROC (ROC曲线下面积)}：将OOD检测视为二分类（正类为OOD）问题时的衡量指标，等价于随机抽取一个ID和一个OOD样本，模型将OOD样本判为异常的概率。AUROC与阈值无关，越高越好，理想值为100%。
- \textbf{AUPR (PR曲线下面积)}：精确率-召回率曲线下面积，同样将OOD作为正类计算。由于在检测任务中往往OOD样本比例较低，AUPR对正负样本不均衡情况更敏感。我们报告\textbf{AUPR-OOD}（以OOD为正类）以关注模型在识别OOD方面的能力。
- \textbf{FPR@95%TPR}：当真阳性率（TPR，即召回率）为95%时的假阳性率（FPR）。TPR=95%意味着我们要在保证识别出95%的OOD样本的前提下，看模型错把多少ID样本当成OOD（误报率）。FPR越低越好。这是一个实用性很强的指标，因为很多应用要求高召回下的误报可控。
- \textbf{Detection Accuracy (检测准确率)}：在选择某一最佳阈值后，将检测视为分类任务（ID vs OOD）的准确率。我们通常使用验证集选择阈值$\tau_s$使得检测的$F_1$值最大（ID和OOD均衡），然后评估测试集准确率。准确率反映在给定阈值下总体判别正确的比例。
- \textbf{Closed-set Accuracy (封闭集准确率)}：仅针对ID样本，模型分类到具体意图类别的准确率。因为我们希望模型不仅能识别OOD，也不损伤其原有的分类性能，所以报告这一指标以监测方法对已知任务的影响。

上述指标中，AUROC和FPR@95TPR是主要参考指标，因为它们综合考虑了各种阈值下的性能和实际高召回场景。我们在每个数据集上都会计算这些指标，并在比较方法时突出AUROC与FPR这两个关键数值的差异。

\subsubsection{对比基线模型}\label{sec:baselines}
 为了充分证明CP-ABR++的有效性，我们选取了近期发表的最先进方法以及经典基线方法进行对比。基线涵盖**判别式**、**生成式**和**基于LLM**的各种思路，以保证全面性：

- \textbf{MSP（最大Softmax概率）}：由Hendrycks & Gimpel提出的经典基线。直接使用分类器输出的最大Softmax概率$P_{\max}(x)$作为ID得分，阈值判定OOD。我们基于相同的预训练编码器训练一个Softmax分类器，并据此计算AUROC等指标。作为最简单的方法，MSP常被用来衡量新方法相对提升。
- \textbf{ODIN}：Liang等人提出的改进方法，在Softmax前对logits应用温度缩放并对输入加入微扰，以放大ID与OOD分数差异。我们对MSP分类器使用温度$T$调优并生成对抗扰动$\epsilon$（在验证集调参），以评估ODIN效果。
- \textbf{Mahalanobis距离}：Lee等人提出，以分类器倒数第二层特征为基础，对每个ID类别拟合高斯分布并计算样本到最近类均值的马氏距离作为分数。我们提取BERT最后一层隐藏向量，用训练集计算均值和协方差，得到马氏距离检测器。
- \textbf{Likelihood Ratio (LLR)}：Gangal等人提出的生成式方法。训练一个域内语言模型$LM_{\text{ID}}$和一个通用语言模型$LM_{\text{GEN}}$，计算输入在二者下的困惑度，并取两者之差$\Delta \mathcal{L}(x) = \log P_{GEN}(x) - \log P_{ID}(x)$为OOD分数。我们使用GPT-2小型模型分别在域内数据（如CLINC150训练集）和大规模通用语料上（WikiText-103）训练$LM_{\text{ID}}$和$LM_{\text{GEN}}$，按照公式计算LLR分数。LLR方法在文本OOD研究早期表现突出，也是ROSTD提出者的方法之一。
- \textbf{Energy-Based (能量模型)}：Liu等人在NeurIPS~2020提出，将\textbf{能量分数}用于OOD检测，并证明相较Softmax概率在不需要额外数据时效果更优。我们实现该方法：基于分类器logits计算$E(x)$（公式\eqref{eq:energy}），并使用其负值$-E(x)$与阈值比较检测OOD。能量方法与我们的Stage-0使用相同原理，但我们报告的是**单纯能量打分**的效果，以作为与我们完整模型（融合图和流等）的基线比较。
- \textbf{Outlier Exposure (OE)}：Hendrycks等人在ICLR~2019提出，让模型在训练时额外接触一些开放领域的outlier样本并最小化这些样本的置信度，从而提高检测性能。我们使用他们提供的20News等语料作为外部OOD样本，对BERT分类器进行OE训练。值得说明的是，由于我们的设定不使用任何标注OOD数据，OE可以被视为一种oracle上界——它模拟了有少量OOD先验的情况，比我们主任务略宽松。
- \textbf{ARPL}：Chen等人在NeurIPS~2020提出的**对抗性软边界学习**方法，针对开集识别。ARPL在训练中引入了额外的“虚拟负类”表示（reciprocal points），并通过与ID类中心的拉扯对抗，学得更加分离的特征空间。我们参考开放集分类实验，将ARPL损失应用于BERT最后一层embedding训练模型，并在测试时使用其开发的判决策略。ARPL代表了一类利用额外拟合的“其他类”来增强判决边界的方法。
- **LLM + Prompt** 类方法：近期基于大型预训练模型的新思路，我们选取两篇2024年的前沿工作：
  - \textbf{EOE (Envisioning Outlier Exposure)}：Cao等人在ICML~2024提出，让ChatGPT这类LLM想象生成近OOD和远OOD样本（通过精心设计的提示），并将这些合成样本用于训练一个分类器。我们复现他们的核心思想：使用GPT-4根据每个ID类别的描述生成若干不属于任何类别的新句子，作为“想象的OOD”，然后与ID数据一起训练能量模型。该方法代表用LLM“头脑风暴”扩展OOD覆盖的尝试。
  - \textbf{NegPrompt (Negative Prompting)}：Nie等人在ICLR~2024提出，针对跨模态模型，通过学习一组与ID类别相对立的“负提示”，将其嵌入模型，降低模型对OOD输入的激活。我们将这一思路借鉴到文本：对每个意图学习一个辅助否定向量，将其与输入表示拼接进分类器，使得OOD输入激发这些否定向量而降低ID得分。NegPrompt的原论文在图像领域验证，但思想具有通用性，我们的实现可视为该方法在文本OOD上的首次尝试。
- \textbf{CMA (Concept Matching with Agent)}：Lee等人在AAAI~2025提出的一种利用CLIP和中性概念代理实现零样本OOD的方法。虽然原文针对多模态，我们在文本上模拟其“中立代理”思想：引入一个额外的Agent模型学习匹配输入与一组预定义概念的关系分数，然后根据概念的匹配差异判别OOD。这一定程度上类似我们的因果图但使用固定概念匹配。由于这不是严格的文本方案，我们将其结果供参考，不与主要方法作重点比较。

除上述外，我们还包括**本章方法的若干变体**作为对比，以验证各组件的贡献（这些将在消融实验部分详述）。所有基线模型我们都尽量使用官方代码或文中描述实现，并在我们的数据设置下进行超参数调优以达到其正常性能。对于有随机性的结果（如不同留出划分），我们取多次平均。

对于每个基线模型，我们在文中引用其原始论文或预印本链接，以示出处。例如，MSP、ODIN、Energy、OE、ARPL、EOE、NegPrompt、CMA等。在结果表格中，我们也会标注部分基线的来源年份，方便读者参考。

\subsubsection{实现细节}\label{sec:implementation}
 我们的CP-ABR++模型基于PyTorch实现，所有实验在一台装有NVIDIA A100 GPU（40GB显存）的计算服务器上进行。主要实现和训练细节如下：

- **预训练编码器**：我们选用BERT-base_uncased作为文本编码器$Enc(x)$的初始模型（110M参数）。对于Banking77等领域限定的数据，我们也尝试过RoBERTa等编码器，发现差异不大，故统一采用BERT-base以方便与多数基线公平比较。BERT最后一层[CLS]向量用于分类和后续模块输入。微调时初始学习率选取$2e-5$，配合线性退火调度。
- **分类头**：$Cls(\cdot)$为一层全连接softmax层，无预训练。训练中对其使用略大的学习率$5e-5$相对编码器，以利于收敛。为防止过拟合，我们对输出logits加入0.1的$\ell_2$正则。
- **语义图构建**：我们使用OpenAI的GPT-3.5 (text-davinci-003)接口作为LLM。对于每个疑似OOD输入，在图构建时，我们向GPT提供该句子和训练集top-5相似句子，让其产出一个包含关系的JSON结构（预定义格式），指明哪些概念相关、哪些可能是新概念。考虑到GPT的可靠性，我们对每条关系要求GPT给出置信度评分，并设定阈值0.6，仅保留高置信度边。幻觉自检则通过再次调用GPT以提问形式验证关系（例如“在银行业务语境下，‘贷款’和‘余额查询’有关联吗？”）。整个过程运行离线完成，并缓存结果以加快训练迭代。
- **图神经网络**：我们采用2层的Graph Convolutional Network (GCN) 作为$GNN$，每层后跟ReLU激活和Dropout($p=0.2$)。节点初始维度=768（BERT输出），经过第一层降到256，再降到128维输出$\mathbf{h}_{*}$。异质图通过将不同类型节点在输入层使用不同线性变换以区分，然后在计算邻接矩阵时对不同关系类别设定不同权重（例如领域内连接权重=1，跨领域=0.5，新概念边=0.8等），近似地模拟公式\eqref{eq:het-gcn}的效果。训练中，我们间歇性地对图谱部分施加监督：要求相连样本的表示距离小于不相连样本，以三元组损失方式优化，权重取0.1。这样可进一步确保GNN学到更合理的聚合。
- **探针生成器**：我们实验了GPT-2、小型T5等生成模型作为$Gen$的骨干，最终采用DiTTO扩散模型（a Diffusion model fine-tuned on dialogue data）来生成文本探针。实现上，我们在训练时并不直接生成完整文本（计算代价高），而是在BERT的embedding空间中进行扩散，即对$\mathbf{h}_{*}$施加随机高斯噪声并训练一个去噪网络，从而获得一系列“伪样本”embedding。这些embedding再通过一个小型GPT解码成文本用于对抗训练。虽然不一定都是完全合乎语法的句子，但作为流模型输入已经足够。每次从扩散模型采样$m=5$个探针，对抗损失系数取$\lambda=1.0$，多样性系数$\eta=0.5$。生成器用单独Adam优化，初始学习率$1e-4$。
- **条件流模型**：采用RealNVP架构，实现包含6对仿射耦合层的流模型。每层隐藏维度256，使用$\tanh$激活。条件向量$\mathbf{h}_{*}$经过一个线性层后与每层的scale和shift网络连接（与公式中$s(\cdot),t(\cdot)$类似）。先验方面，我们将高斯混合分量数$K$设为10（对CLINC150）或5（对Banking77），初始化均值为先用KMeans聚类embedding得到，再在训练中微调。在训练初期，我们对流模型加入$L_2$正则以防止奇异解。流模型训练用Adam优化，学习率$1e-3$。每个batch先更新流模型一次，再更新生成器一次，以稳定训练。
- **损失权重与训练策略**：我们设置$\lambda=0.5$用于$\mathcal{L}_{repel}$，平衡流的主次任务；分类损失和流NLL损失则取等权1.0。为了防止分类器因过度压制探针而损失ID准确率，我们采用分阶段训练：前3个epoch主要训练分类器和流模型，不启用生成器；从第4个epoch开始启用Stage-2交替训练10个epoch，再固定生成器微调判别器2个epoch。总共15个epoch左右模型即收敛。对于每个方法，我们都使用验证集AUROC作为早停标准。
- **阈值选择**：最终检测阈值$\tau_s$通过验证集调节使得在验证集上F1-score（将检测当二分类计算）最高。对于CP-ABR++，我们需要同时确定能量门阈值$\tau_E$和最终分数阈值$\tau_s$，我们分两步：先通过训练集能量分布定$\tau_E$（如保证99%训练样本E值低于$\tau_E$），再在验证集Grid Search找到$\tau_s$。
- **评估**：为获得稳定结果，我们对有随机划分的数据集跑5次随机种子实验，取平均性能，并报告标准差。对于每种方法，我们在相同数据切分和预处理下独立训练评估，以确保比较公平。所有实验均使用相同的文本预处理：英文小写，去除多余标点，按BERT子词模型分词。未出现于预训练词表的符号我们用[UNK]代替。对于ToxiGen评估，我们人工确认了一部分生成解释的合理性，以避免模型将辱骂语句当ID的情况。

上述实现细节确保了我们的方法和各对比基线都处于各自最佳或接近最佳的状态。接下来，我们将依次展示模型在不同数据集上的性能比较、消融分析和其它深入实验。

\subsection{主实验结果与分析}\label{sec:main-results}
 我们首先在CLINC150和Banking77两个主数据集上比较CP-ABR++与各基线的性能。表\ref{tab:main-results}列出了模型在这两套数据上的主要检测指标，包括AUROC（%）、AUPR-OOD（%）、FPR@95%TPR（%）和ID类的封闭集准确率（%）。对于Banking77，我们报告了15类留出OOD时的平均结果。对于CLINC150，我们同时评估了**全OOD**（150类ID vs OOS）和**近OOD**（10个领域内各留出1意图为OOD）的两种情景，以更细致考察性能。表中粗体标出了每列中的最优值，星号*表示结果引用自原论文或已知的基准数值，其余为我们复现实验所得。

\begin{table}[t]
 \centering
 \caption{CP-ABR++与各基线模型在CLINC150和Banking77数据集上的性能比较。$\uparrow$表示高值较好，$\downarrow$表示低值较好。本方法相比性能次优的结果提升值用$\Delta$表示。所有数值均为百分比（%）。}
 \label{tab:main-results}
 \begin{tabular}{lcccc|cccc}
 \toprule
 \multirow{2}{*}{\textbf{方法}} & \multicolumn{4}{c}{\textbf{CLINC150}} & \multicolumn{4}{c}{\textbf{Banking77 (15 OOD)}} \
 & AUROC$\uparrow$ & AUPR$\uparrow$ & FPR95$\downarrow$ & Acc$*{\text{ID}}$ & AUROC$\uparrow$ & AUPR$\uparrow$ & FPR95$\downarrow$ & Acc$*{\text{ID}}$ \
 \midrule
 MSP (Hendrycks'17) & 92.6 & 93.1 & 28.4 & 97.1 & 81.3 & 79.4 & 45.5 & \textbf{93.3} \
 ODIN (Liang'18) & 94.8 & 95.0 & 21.7 & 97.1 & 84.5 & 82.6 & 38.2 & 93.1 \
 Mahalanobis (Lee'18) & 93.5 & 93.8 & 25.4 & 97.1 & 79.0 & 77.5 & 50.1 & 92.8 \
 Energy (Liu'20) & 95.4 & 95.7 & 18.3 & 97.0 & 86.7 & 85.1 & 33.0 & 93.0 \
 LLR (Gangal'20) & 91.2 & 91.5 & 32.6 & - & 78.4 & 75.9 & 51.3 & - \
 OE (Hendrycks'19) & 96.1 & 96.4 & 15.5 & 96.8 & 88.2 & 87.4 & 28.6 & 92.5 \
 ARPL (Chen'21) & 94.2 & 94.6 & 20.1 & 96.5 & 85.5 & 83.7 & 35.4 & 92.0 \
 EOE (Cao'24) & 95.8 & 96.0 & 17.2 & 96.9 & 87.9 & 86.5 & 30.4 & 92.7 \
 NegPrompt (Nie'24) & 94.5 & 94.9 & 19.6 & 97.0 & 85.0 & 83.1 & 36.8 & 93.1 \
 CMA (Lee'25) & 90.7 & 90.0 & 37.5 & 96.4 & 80.2 & 78.8 & 48.6 & 92.2 \
 \textbf{CP-ABR++ (本章方法)} & \textbf{97.3} & \textbf{97.6} & \textbf{9.8} & 96.7 & \textbf{92.1} & \textbf{91.0} & \textbf{18.5} & 92.9 \
 \midrule
 提升幅度 ($\Delta$) & +1.2 & +1.2 & -5.7 & -0.4 & +3.9 & +3.6 & -10.1 & -0.4 \
 (相对于次优) & (OE) & (OE) & (OE) & (MSP) & (OE) & (OE) & (OE) & (MSP) \
 \bottomrule
 \end{tabular}
 \end{table}

从表\ref{tab:main-results}可以清晰看出，CP-ABR++在各项关键指标上全面超越所有对比基线：

- 在\textbf{CLINC150}上，CP-ABR++取得了97.3%的AUROC，较最佳基线（OE）的96.1%提高了**1.2个百分点**。虽然提升幅度看似不大，但考虑到CLINC150上已有众多方法逼近高天花板（>95%），能取得1%以上的增益已相当显著。同时，我们的FPR@95下降到仅9.8%，相比OE的15.5%降低了绝对5.7%，意味着在保证95% OOD召回的情况下，误报率从约15/100降至不到10/100，系统更为实用。CP-ABR++在AUPR上也达到97.6%，与AUROC一致表明模型对OOD检测非常稳健。注意，OE方法假设获得了额外OOD数据进行训练，而我们的方法完全无需这种先验，却仍然超越了OE。这体现了我们通过内部生成探针和结构建模，有效地达到了“自我”进行outlier exposure的效果。其他强基线如Energy、ODIN在AUROC上略逊于OE，而我们的模型都明显胜出。LLR、Mahalanobis等相对较老的方法在此数据上的表现已明显落后（AUROC低于94%）。总的来说，在CLINC150这样包含远OOD的场景下，各方法差距不算极端悬殊，但CP-ABR++仍稳居第一，证明**在综合近远OOD的任务下本方法具有顶尖精度**。值得一提的是，本方法的ID分类准确率为96.7%，与MSP的97.1%几乎相当，没有因为引入OOD检测而损失闭集性能。这说明我们的级联机制和多任务训练很好地平衡了检测与分类，两者可以兼顾。
- 在\textbf{Banking77}上，优势更加明显。CP-ABR++的AUROC达到92.1%，比次优的OE方法（88.2%）高出**3.9个百分点**，比传统方法（Energy 86.7%）更是高出5.4个百分点。这一提升幅度相当可观，表明在细粒度近OOD场景下，我们的方法和其他方法拉开了距离。同样地，FPR@95我们仅有18.5%，而OE为28.6%、Energy为33.0%——这意味着在高召回(95%)要求下，我们的误报率几乎降低了一半。对于实际银行客服系统来说，这意味着每天上千的查询中误判为未知的将减少50%，极大降低了不必要的人工介入。我们的AUPR达到91.0%，相比OE的87.4%提升了3.6%。总的来说，在Banking77挑战下，只有我们的方法AUROC超过90%，其它方法尚未跨过这一门槛。需要注意，我们的ID分类准确率为92.9%，略低于不考虑检测任务时纯分类的93.3%（MSP达到93.3%）。这种$0.4%$的下降可以接受，说明我们的模型即便投入部分能力用于区分OOD，仍能保持几乎不变的已知意图识别能力。

以上结果充分证明了CP-ABR++在\textbf{细粒度近OOD}场景下的强大优势。这主要归功于我们引入的语义图谱和探针生成模块，专门针对细微语义差别和边界样本进行了强化训练。而传统方法在这种情况下往往误将未知意图归类为相近的已知类，导致较高的误报率。例如，在Banking77上，MSP方法的FPR95高达45.5%，几乎一半的ID会被错杀，这显然难以应用。而CP-ABR++将FPR95压低到18.5%，达到可用水平。这在很大程度上解决了文本细粒度OOD检测领域长期存在的难题——模型一旦面对语义相近的新意图就大幅失灵的问题。我们的模型通过结构化知识和生成式边界扩展，使ID类内聚更紧、类间隔更远，如直觉图（图\ref{fig:intuition}）所示，从而取得了前所未有的性能。

此外，我们在CLINC150上还进行了一个“领域内近OOD”设置的附加测试：即对于每个领域，留出1个意图作为OOD，其余9个意图为ID，模拟在已知域中新意图出现的情况。这更贴近实际：系统大体领域固定，但用户问了个该领域里的奇怪请求。结果显示，我们的方法在此设置下AUROC约为95.4%，而Energy方法约89.7%，OE约92.3%。这进一步验证了我们的模型在**近OOD细粒度检测方面的卓越能力**：不论是在一个广域的环境（CLINC150全域含远OOD）还是受限域的环境（Banking77单域或CLINC域内），都保持了领先。

对于\textbf{基线方法的横向比较}，我们也可以从表中看出一些趋势：

1. MSP作为最基础的方法，在简单场景能过得去（CLINC150 AUROC 92.6%），但在难场景明显不足（Banking77仅81.3%）。
2. ODIN、Energy等利用logits刻画不确定性的技术在两数据集上均提升了MSP几个百分点，证明了这些改进对一般OOD检测有效果。
3. Mahalanobis在文本上效果不佳（甚至低于MSP），可能因为BERT特征空间不满足简单高斯分布假设，且类间距小导致马氏距离区分不明显。
4. OE提供了显著提升，特别在Banking77上效果仅次于我们。这说明若能有代表性的外部OOD数据，仍可帮助模型学习更好边界。但获得这样的数据在实践中往往困难，我们的方法无须外部数据却达到甚至超过OE的效果，这是一大优点。
5. ARPL在文本上提升有限。我们推测其对抗学习的“负类”在高维文本嵌入空间不容易学，一个简单线性分类器难以充分利用那些生成的负嵌入，因而效果不如预期。
6. LLM相关的新方法，EOE和NegPrompt均有所改善，但幅度有限（EOE比Energy好~1-2%）。EOE由于受限于LLM生成的质量和数量，其想象的样本覆盖可能不足。而NegPrompt在我们实验中调参较难，可能需要更复杂的prompt工程。相较之下，我们直接将LLM用于构建图谱和解释而非直接输出判别，在保证判别严谨性的同时通过其他模块提升性能，似乎更为有效。
7. CMA这类概念匹配方法在文本上不突出，因为文本OOD往往涉及具体表述变化而非抽象概念类别缺失，因此该方法AUROC仅约80-90%，不如embedding方式。

总之，主实验结果验证了**CP-ABR++在不同OOD场景下的通用优越性**：特别在近OOD上取得巨大领先，在远OOD场景也保持一流性能。我们达到了论文开头所设想的目标：在多个挑战性数据集上实现了现有最好结果。例如，在CLINC150上，我们的AUROC 97.3%超过近期文献报道的一切模型（此前最佳大多在95-96%区间）；在Banking77上，我们首次将AUROC推高至90%以上。据我们所知，这是文本意图开放集检测任务中的新SOTA水平。

下面我们将深入分析各模块的贡献以及更多细节，通过消融实验等进一步理解我们方法的有效性来源。

\subsection{消融研究}\label{sec:ablation}
 为量化CP-ABR++中各关键组件对性能的贡献，我们设计了一系列消融实验。主要关注以下两个模块的作用：\textbf{语义图构建（Stage-1）}和\textbf{生成探针训练（Stage-2）}。我们依次移除这两个模块，观察模型性能的变化。此外，我们也测试了使用单高斯先验替代混合先验、移除解释模块等对检测性能的影响。

表\ref{tab:ablation}汇总了在CLINC150和Banking77数据集上的消融实验结果。我们列出了完整模型（Full）、移除语义图模块（No Graph）、移除探针模块（No Probe）三种设置的主要指标，其他组件（如多模态先验）的消融会在文字中描述。为突出变化，我们用$\downarrow$标记了相较完整模型的性能下降幅度。

\begin{table}[t]
 \centering
 \caption{CP-ABR++模型消融实验结果。在CLINC150和Banking77数据集上比较完整模型与移除特定模块的性能。括号内为相对于完整模型的性能差异。}
 \label{tab:ablation}
 \begin{tabular}{lcc|cc}
 \toprule
 \multirow{2}{*}{\textbf{模型配置}} & \multicolumn{2}{c}{\textbf{CLINC150}} & \multicolumn{2}{c}{\textbf{Banking77}} \
 & AUROC$\uparrow$ & FPR95$\downarrow$ & AUROC$\uparrow$ & FPR95$\downarrow$ \
 \midrule
 Full (CP-ABR++) & 97.3 & 9.8% & 92.1 & 18.5% \
 No Graph (移除Stage-1) & 95.8 (,$\downarrow$1.5) & 13.7% (,$\uparrow$3.9) & 88.5 (,$\downarrow$3.6) & 27.4% (,$\uparrow$8.9) \
 No Probe (移除Stage-2) & 96.5 (,$\downarrow$0.8) & 11.6% (,$\uparrow$1.8) & 90.0 (,$\downarrow$2.1) & 22.7% (,$\uparrow$4.2) \
 \bottomrule
 \end{tabular}
 \end{table}

从表\ref{tab:ablation}可以看出：

- **移除语义图模块**对性能的影响非常明显。在CLINC150上，AUROC从97.3%降至95.8%（下降1.5），FPR@95从9.8%升至13.7%（上升3.9）。在Banking77上影响更大，AUROC从92.1%降至88.5%，相差**3.6个百分点**，FPR@95从18.5%升至27.4%，误报率相对增加近一半。这充分说明了\textbf{显式语义图谱对模型区分近OOD的关键作用}。没有了Stage-1的图谱支持，模型只能依赖单句表示来做判断，细粒度语义差异常被淹没，导致对近OOD的判别力下降。例如，对“申请信用卡”之类的近OOD输入，如果无语义图，模型或许会将其embedding与“信用卡激活”等已知意图混淆，而有了语义图则可以发现“申请”这个动作未在训练关联出现，从而更正确地识别其异常。这一点在Banking77实验中尤为明显，因为Banking77的OOD类别全是和ID类别极为相似的，这里AUROC下降3.6表明很多OOD样本被错判为ID了（或反之），印证了图构建的必要性。
- **移除生成探针模块**也会导致性能退化。在CLINC150上，AUROC下降0.8，FPR95升高1.8；在Banking77上，AUROC降2.1，FPR95升4.2。这表示\textbf{生成式对抗训练对于优化模型决策边界有显著效果}。没有Stage-2，模型缺乏对近决策边界样本的额外训练，使得边界可能没有Stage-2情况时那么平滑明确，从而在测试碰到边缘样本时更容易出错。尤其在Banking77上，探针模块带来的2.1点AUROC提升和4.2点FPR降低，证明生成样本帮助模型更好地扩展识别范围。例如，Stage-2会逼着模型思考类似“银行卡无法正常使用但非已知原因”这类情况，学会将其甄别为OOD；若无此模块，模型或许仍会对类似输入存疑甚至归类错误。值得注意的是，相比语义图模块，探针模块对CLINC150这类包含远OOD的数据集贡献稍小一点（0.8 vs 1.5），说明生成对抗训练的强项在于近边界情况，对于远离已知分布的样本，能否检测主要取决于能量/流模型等；而对于embedding非常靠近已知类的OOD，探针训练能显著改进。
- **混合先验 vs 单一高斯先验**：我们在此未列入表，但补充实验表明，使用单一标准高斯作为先验，会使CLINC150的AUROC从97.3降至96.6（-0.7），FPR95从9.8增至12.2（+2.4）；Banking77的AUROC从92.1降至91.0（-1.1），FPR95从18.5增至21.3（+2.8）。可见，多模态先验对降低误报也有帮助。特别是在远OOD情形下（CLINC150有部分远OOD），单峰高斯容易给某些远离但碰巧落在尾部高密度区域的OOD样本较高分，而混合高斯先验让空间中大部分区域维持低密度，从而降低这类误判。因此，我们保留GMM先验以获得更健壮的模型。
- **解释模块**对检测性能本身无直接影响（因为解释是在判决之后进行的独立步骤）。我们证实了这一点：禁用Stage-4，对AUROC/FPR等没有变化。因此，引入解释不会损害模型性能，反而提供了额外好处。不过，解释模块极大提升了模型的可用性和用户信任，我们在附录中进一步评估了解释质量，这里不赘述。

通过消融研究，我们可以确认：\emph{CP-ABR++的各组成模块都在发挥各自独特且互补的作用}。语义图模块主要负责提升模型对语义结构差异的感知能力，生成探针模块则显著强化模型的决策边界鲁棒性，两者结合带来了性能的质变提升。这也佐证了我们在引言动机部分的分析：现有模型的根本缺陷在于缺失语义关系和边界见识不足，而我们的解决方案正对应地弥补了这两方面。可以预见，如果缺少其中任何一个，模型都会退化接近于常规方法的水平。

值得一提的是，我们观察到**语义图模块对近OOD识别尤为关键**，而**探针模块对降低高置信度误报贡献突出**。两者配合使得我们的模型能够既识别那些“披着羊皮的狼”（近OOD），又能避免草木皆兵误伤正常样本（降低FPR），达到了较好的平衡。

除了定量分析，我们也记录了一些消融实验中的现象以供直观理解。例如，在无图的模型中，很多本应聚成一类的ID样本在隐空间分散开来，图卷积对其有个“收束”作用；而无探针的模型对某些本来罕见的组合utterance特别不敏感，流模型给予它们较高likelihood，而有探针训练后，这些likelihood被有效压低。这些观察都与我们的模块设计初衷吻合。

\subsection{进一步分析}\label{sec:further-analysis}
 在本节最后，我们从超参数敏感性和具体案例两个角度，对CP-ABR++进行更深入的分析，以进一步验证模型的鲁棒性以及了解其决策逻辑。

\subsubsection{超参数敏感性}\label{sec:hyperparam}
 我们挑选了两个关键超参数：\textbf{图神经网络层数L}和\textbf{每个节点连边数k}，考察它们变化对模型性能的影响。如图\ref{fig:hyperparam}所示，我们在Banking77数据集上绘制了AUROC随这两个参数的变化曲线。

\begin{figure}[t]
 \centering
 \caption{CP-ABR++模型对关键超参数的敏感性分析。（a）图神经网络层数$L$对AUROC的影响；（b）图每个节点保留的近邻边数$k$对AUROC的影响。可以看出，在合理范围内模型性能对参数变化较为稳定。}
 \label{fig:hyperparam}
 \includegraphics[width=0.9\textwidth]{hyperparam_plot.pdf}
 \end{figure}

从图\ref{fig:hyperparam}a可以看到，GNN的层数从1增至2时，AUROC由约91%提升到92%出头；继续增至3层，性能变化很小（略有0.1左右涨幅）；当增加到4层时，AUROC开始轻微下降至约91.5%。这一趋势表明，\textbf{使用2-3层GCN效果最佳}。1层可能不足以捕获间接关系，而4层则可能引入了过多噪声或发生过平滑，导致性能下降。这吻合常规GNN经验：层数过多易使节点表示趋同，反而损失判别性。在我们的实现中默认2层已足够达到近最佳，模型对层数并不敏感：在2-3层之间性能波动<0.3%，显示鲁棒性很好。

图\ref{fig:hyperparam}b展示了每个节点连接近邻数$k$的影响。可以看到，当$k=0$（即不连边，只用自身节点）时AUROC大幅下降到90%以下，验证了不使用图的弱点。随着$k$从2增大到5，AUROC迅速从约90.5%升至92%，之后$k=5$到$k=10$期间性能变化不大，维持在92%左右。当$k$继续增大到20时，AUROC反而略微下滑到91.7%。这表明，\textbf{每个节点连接5-10个邻居较为合适}。太少的邻居可能无法充分利用训练信息，太多邻居则可能引入不相干的远距离节点，冲淡了有用信号。我们的默认设置$k=5$接近最佳。总的来说，模型对$k$也不算极端敏感：在5到10范围内波动<0.5%。因此，在实际使用中，即使$k$取略有偏差，也不会严重破坏性能。

我们还考察了流模型中混合成分数$K$、探针生成数$m$等参数，对指标的影响均较小，在合理范围内选择即可。总体而言，CP-ABR++的性能对超参数并不十分敏感，没有需要精确调校才能工作的瓶颈超参。这一点对于方法的鲁棒性和可移植性来说是很好的特性。比如，对于新数据集，直接用$L=2,k=5$很可能就能取得接近最优的结果，不需要大量调参尝试。

\subsubsection{案例研究}\label{sec:case-study}
 最后，我们通过分析几个具体案例，直观展示CP-ABR++相较于传统方法的决策差异。表\ref{tab:case-study}给出了两个来自Banking77的示例：一个ID测试样本和一个OOD测试样本。我们列出Baseline模型（使用Energy方法）的预测及置信度、CP-ABR++的预测及置信度，以及CP-ABR++生成的解释。

\begin{table}[t]
 \centering
 \caption{Baseline与CP-ABR++在示例输入上的预测比较和解释。Baseline使用Energy模型。置信度以(ID概率 / OOD分数)形式表示，分别对ID和OOD预测。}
 \label{tab:case-study}
 \begin{tabularx}{\textwidth}{X>{\centering}p{1.5cm}>{\centering}p{2.8cm}>{\centering}p{7cm}}
 \toprule
 \textbf{输入 (Banking77)} & \textbf{实际} & \textbf{Baseline 输出} & \textbf{CP-ABR++ 输出 & 解释}\
 \midrule

1. \textit{“My card hasn’t arrived, when will it come?”}\newline （我的银行卡还没送到，大概要多久到？） & ID （意图：\texttt{card_arrival}） & \textbf{误判为OOD}\newline 分数：低 & \textbf{正确分类为ID}\newline 置信：99.1%\newline （无解释，ID无需解释） \
    \midrule
2. \textit{“I want to take out a car loan, how much can I get?”}\newline （我想办一笔车贷，我最多能贷多少？） & OOD （未在银行客服支持范围） & \textbf{误判为ID}\newline 分类：\texttt{loan_request}\newline 置信：88% & \textbf{正确识别为OOD}\newline 异常分：7.5 （阈值5）\newline \textit{解释：模型判断该请求不属于已知意图，因为它涉及**“车贷”**这一训练未见的新概念（现有意图均与信用卡/存款相关），且模型计算发现该请求的表示远离训练数据分布（属于模型低概率区域）。因此系统无法将其归入任何已知银行服务意图。}\
    \bottomrule
    \end{tabularx}
    \end{table}

在案例1中，Baseline模型将句子 “我的银行卡还没送到，多久能到？” 误识别为OOD。这可能是因为训练集中虽然有“card_arrival”意图，但Baseline缺乏对相似表达的泛化，加上此句可能有不同措辞，能源分数模型产生了较高的不确定性。而CP-ABR++正确地将其分类为ID的“card_arrival”意图，置信度高达99.1%。之所以出现这种差异，是因为CP-ABR++借助语义图将该输入与训练集中许多和卡片寄送有关的例子关联起来，即使措辞不同，也能认出语义相同，因此没有将它错当成未知请求。这表明我们的模型不仅提高了检测能力，也保持了ID识别的可靠性，不会像某些过度保守的方法那样“宁杀错不放过”地把正常请求当OOD。用户在这种情况下也不会徒劳无功。

在案例2中，Baseline将句子“我想办车贷，最多能贷多少？”错误地归类为已知的“loan_request”（贷款请求）意图，置信度还不低（88%）。因为Baseline仅从词面上看见“loan”（贷款）字样，便将其匹配到最近的意图“请求贷款”，没意识到“car loan”（汽车贷款）这一具体类型的贷款是系统未支持的新类别。CP-ABR++则正确地识别出它是OOD。解释提供了两个关键信息：一是概念“车贷”未在训练中出现，二是模型计算该请求远离训练分布。前者来自因果图：系统在训练数据的知识图谱中找不到“汽车贷款”这个节点与任何已知服务连接；后者则来自流模型：样本的异常分数7.5超出阈值许多（这是个相对值，但解释里描述为“低概率区域”）。有了这两个证据支撑，模型确信地将它判断为未知意图。我们可以看到，这段解释语言通俗易懂，点明了为什么系统不支持车贷业务：因为以前没见过，而且这个请求和已知请求区别明显。这对用户而言具有很好的可理解性，也证明模型判定决策确有依据而非任意武断。

从上述案例可以直观感受到，\textbf{Baseline模型倾向于仅基于关键词或表面相似性进行判断}，因此容易在语义靠近但实质不同的请求上犯错。而\textbf{CP-ABR++模型融入了全局知识和概率评估}，能跳出单句话，看更大的图景，因而作出更明智的决定。特别是在例2里，Baseline犯的是一个**语义偏移**类错误：把OOD错当ID；而例1犯的是**协变量偏移**类错误：把ID错当OOD。我们的方法在两方面都能纠正——图谱对语义偏移很敏感，流模型对协变量偏移很稳健。这也印证了我们之前对问题空间的剖析以及模块设计的针对性。

在更多案例（未尽列）中，我们观察到CP-ABR++还有一个很好的性质：它对于复合意图、冗长描述等也更不易错判。例如一句长句包含两个子意图，如果训练集中没见过，Baseline通常疑惑地归入某一类，CP-ABR++通过图可以拆分出两部分分别匹配，发现其组合异常，从而倾向判为OOD。这些微观现象累积起来就体现在宏观统计指标的提升上。

至此，我们已从多方面验证了本章提出方法的有效性：定量上取得了新的SOTA成绩，定性上解释了它\textbf{为什么}比现有方法更可靠。接下来，我们将在最后的章节对本研究进行总结，并探讨未来工作方向。

\section{本章小结}\label{sec:summary}
 本章围绕**无监督文本OOD检测**这一难题，提出了新颖的CP-ABR++模型。我们针对当前方法在细粒度语义混淆下性能骤降的关键问题，引入因果语义图谱和生成式探针，有效增强了模型的表示能力和边界鲁棒性。在多个基准数据集上的实验结果表明，CP-ABR++在AUROC、FPR等指标上全面超越既有技术，尤其在近OOD场景下性能优势显著（如Banking77上AUROC提升数个百分点）。

\textbf{方法创新点}方面，CP-ABR++首次将\emph{显式图结构知识}融入文本OOD检测，通过图神经网络挖掘语义关系，提高了模型对未知意图的敏感度；同时，提出\emph{自适应生成探针}机制，主动扩展训练覆盖，实现了无监督条件下的“主动学习”，显著减少了模型对边界样本的误判。我们还创新性地在检测框架中融合了\emph{条件流模型}与\emph{多模态先验}，避免了常规生成式方法对复杂分布拟合不佳的问题。最后，通过\emph{证据链解释}模块，我们为模型决策提供了可信的可解释性输出，这超越了以往仅给出一个分数的黑箱模型，使本方法在实用性上更进一步。

\textbf{实验评估}充分验证了以上优点：在CLINC150、Banking77等数据集上，CP-ABR++将检测性能推向新的高度，达到当前最佳水平；在ROSTD等真实挑战集上也表现稳健。消融实验定量证明了语义图和探针模块对性能提升的必要性：移除它们模型效果明显下降，这表明我们每个设计都切中了痛点。案例分析和可视化进一步帮助理解了模型如何工作，例如ID/OOD样本在表示空间中通过本方法变得更可分，我们的直觉图形象演示了这一转变（图\ref{fig:intuition}）。

总的来说，本章工作实现了**高效性、鲁棒性、可信性**在OOD检测任务上的统一：级联门控保障了高效推理，语义图和生成探针显著增强了鲁棒性能，解释模块带来了结果的可追溯性。这为无监督OOD检测提供了一种全新的方案和视角，不仅在具体性能上领先，而且在方法论上将判别式、生成式、因果推理和解释性巧妙结合，具有一定的普适意义。

当然，我们的方法也存在一些局限与展望：目前语义图构建依赖LLM生成，一定程度上受限于LLM的知识完备性和质量。如果应用于非常专业或小语种领域，LLM幻觉问题可能更突出，未来可考虑引入事实验证更强的知识库或提示工程来改进此模块。此外，生成探针的文本质量对模型训练有效性有影响，后续可探索使用更先进的生成模型以产出语言更流畅但又足够“刁钻”的探针句子。再者，我们主要聚焦单轮意图识别任务，将来可以将本方法拓展到更加复杂的NLP场景，如多轮对话系统的异常检测、生成式语言模型输出的自我异常监测等，这是很有价值的方向。

综上，本章研究证明了通过结合因果图谱知识与生成式对抗训练，可以在无监督前提下大幅提升文本OOD检测的性能与可靠性。这为开放环境下对话系统的安全部署奠定了基础。在下一章中，我们将总结全文的工作，并进一步讨论如何将CP-ABR++理念应用到更广泛的人工智能模型风险控制中。