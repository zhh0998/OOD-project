===FILE: chapters/chapter5.tex (Part 1/12)===
 \chapter{提出的方法与实验}\label{chap:5}

\section{引言}\label{sec:5-1}
 在真实应用场景中，分类模型经常会遇到超出训练分布范围的输入，即所谓分布外数据（Out-of-Distribution, OOD）。深度神经网络（DNN）已在许多任务上取得高精度，但已知在面对OOD输入时往往依然给出过度自信的错误预测 。例如，在图像分类中即便输入是噪声或无关图片，模型的softmax输出也可能呈现高度自信的某一类概率 。这会带来安全风险，因此能够可靠检测OOD输入并拒绝输出预测，对开放环境下部署的模型来说至关重要 。尤其在\textbf{意图识别}等自然语言处理任务中，当用户查询不属于任何已知意图时，系统应当及时判断“域外”并拒答，否则可能产生驴唇不对马嘴的回答，影响用户体验甚至引发严重后果。

近年来，大量研究围绕OOD检测展开。在视觉领域已有诸多探索，而针对文本的OOD检测关注较少 。传统方法多采用\textbf{后验概率}的不确定性来区分OOD，例如最大softmax概率（MSP）被作为检测基线 。Hendrycks和Gimpel提出的MSP基线无需额外训练即可应用于任何分类器 ；然而它表现有限，后续工作通过\textbf{后处理校准}显著提升了检测性能。例如，Liang等提出ODIN方法，在输入添加小扰动并采用温度缩放，从而更好地分离ID与OOD样本的softmax分布  。在图像任务上，ODIN将某模型在95%TPR时的误报率从34.7%大幅降低至4.3%  。此外，利用模型输出的\textbf{能量}而非概率作为分数也是一条有效途径 。能量分数与输入数据密度有更明确的理论联系，并且不易受过度自信问题的影响 。Liu等人构建了统一的能量OOD检测框架，在不同模型上均取得优于软max分数的性能，平均将FPR$_{95}$降低了18% 。另一方面，也有方法在训练中引入额外的\textbf{外部异常数据}来提升检测器的泛化性能（称为\textbf{开放集训练}）。典型如Hendrycks等提出的Outlier Exposure（OE）策略，利用一个辅助的未标注开放语料对模型进行带“拒识”类别的训练，从而显著改善在新奇样本上的检测性能  ；后续研究也验证了该策略的有效性和鲁棒性 。不过，开放集训练要求精心挑选代表性强的外部数据 ，在实际中未必总能获得。此外，在自然语言领域还存在利用\textbf{大模型零样本能力}的思路。例如，有研究系统评测了ChatGPT等LLM在零样本和小样本OOD意图检测上的性能，发现虽然LLM无需专门训练即可利用强大的语言理解能力区分域外意图，但在充分数据场景下仍明显劣于有监督微调模型  。LLM的判别结果对提示语和评分标准也较为敏感，缺乏稳定的阈值判定方案，这使得与传统方法直接比较存在困难。

综上所述，现有方法各有局限：基于后验概率的方法易受过度自信影响，而引入温标、扰动或能量等技巧虽有效但仍仅利用了判别分布$P(y|x)$的信息；引入外部数据的方法依赖额外资源且选择困难；大模型零样本方法灵活但欠缺可比的决策置信度。尤其针对\textbf{中文意图识别}场景，目前尚缺乏充分研究和专门优化的OOD检测方法。因此，本章针对这一问题，提出一种\textbf{双编码器级联}的OOD检测新框架，包括能量门控、语义图增强、对抗探针生成、流模型判别四个阶段，辅以一系列针对文本的正则化损失。与已有方法相比，我们的方法在不使用额外OOD数据的条件下，实现了对远域和近域OOD的高效识别，并显著领先现有各类基线。在本章中，我们将详细介绍该方法的模型结构和训练目标（第\ref{sec:5-2}节和第\ref{sec:5-3}节），给出完整的实验评估，包括与最新方法的统一指标比较、消融分析和统计显著性检验（第\ref{sec:5-4}节），探讨实际部署的精简方案和注意事项（第\ref{sec:5-5}节），以及伦理影响和复现细节（第\ref{sec:5-6}节）。

===FILE: chapters/chapter5.tex (Part 2/12)===
 \subsection{四阶段推理流程与算法描述}

为了更清晰地刻画本方法的检测流程，我们在算法\ref{alg:cascade}中给出了Pseudo-code摘要，并以(a)、(b)、(c)三部分标注对应四个阶段的关键步骤。其中(a)部分对应Stage-0的能量门控筛选操作；(b)部分涵盖Stage-1异质语义图融合和Stage-2探针生成的主要过程；(c)部分对应Stage-3的流模型密度计算与最终判别。可以看到，经过能量门控后，仅怀疑为OOD的样本才进入后续复杂步骤，从而优化整体检测的延迟和吞吐。完整的模型参数学习则涉及多项损失函数，将在下一节详细介绍。

\begin{algorithm}[htbp]
 \caption{文本OOD检测级联流程（Pseudo-code）}
 \label{alg:cascade}
 \KwIn{输入文本 $x$；预训练判别模型 $F$（如DeBERTa）；句向量模型 $G$（如E5/GTE）；能量阈值 $\tau$；流模型 $\mathcal{F}$；GMM先验参数 ${\pi_k, \mu_k, \Sigma_k}*{k=1}^{K}$}
 \KwOut{OOD判定结果或置信分数 $s(x)$}
 % Stage-0
 计算 $E(x) = -T \log \sum*{y}\exp(F_y(x)/T)$ （能量分数，$T$为温度）;
 \uIf(\tcp*[f]{(a) Stage-0: 能量门控筛选}){$E(x) > \tau$}{
 \Return $\text{OOD}$ \tcp*{能量高于阈值，直接判定OOD}
 }
 $\mathbf{h} \leftarrow G(x)$ \tcp*{句向量嵌入}
 构建语义图$\mathcal{G}=(V,E)$，含文本节点 $v_x$ 表示 $\mathbf{h}$，以及概念节点表示与$x$相关的词义 ;
 利用图神经网络更新节点表示，得到融合后的文本表示 $\mathbf{h}^*$ \tcp*{(b) Stage-1: 异质语义图融合}
 基于 $\mathbf{h}^*$ 生成对抗探针 $\tilde{x}$，使 $F(\tilde{x})$ 信心下降且保持与 $x$ 在语义上的接近 \tcp*{(b) Stage-2: 探针生成}
 $\mathbf{z} \leftarrow \mathcal{F}(\mathbf{h}^*)$ \tcp*{流模型将表示映射到潜空间}
 计算 $p_X(\mathbf{h}^*) = \left[\sum_{k=1}^K \pi_k \mathcal{N}(\mathbf{z}; \mu_k,\Sigma_k)\right] \left|\det \frac{\partial \mathcal{F}}{\partial \mathbf{h}^*}\right|^{-1}$;
 计算 $s(x) = -\log p_X(\mathbf{h}^*)$ \tcp*{(c) Stage-3: 计算异常分数}
 \uIf{$s(x) > \delta$}{
 \Return $\text{OOD}$ \tcp*{密度低于阈值，判定OOD}
 }\Else{
 \Return $\text{ID (in-distribution)}$
 }
 \end{algorithm}

如算法\ref{alg:cascade}所示，本框架严格区分了不同功能的模块，使模型具备良好的扩展性和可解释性：Stage-0模块可视作在原分类器基础上添加的“不确定性门”，仅需一条能量阈值即可起效，易于实现和部署；Stage-1模块通过引入外部知识（类名、同义词、关联词等）增强模型对语义偏离的感知，其图结构有助于可视化理解OOD判定依据；Stage-2模块生成的探针可以看作对模型决策边界的主动试探，提供了一种生成式的近域异常样本分析手段；Stage-3的流模型则提供了统一的概率测度，使不同来源的信息融合到异常分数上。接下来，我们将深入描述各模块的设计细节和相应的训练目标。

------

===FILE: chapters/chapter5.tex (Part 3/12)===
 \section{模块细化与损失函数设计}\label{sec:5-3}
 本节按照Stage-0到Stage-3的顺序详细介绍模型的关键模块和训练损失。符号方面，我们统一用$\mathbf{h}$表示嵌入分支输出的文本表示向量，用$E(x)$表示判别分支输出的能量分数，用$s(x)$表示最终的OOD分数。

\subsection{Stage-0：判别式能量门控}\label{sec:5-3-1}
 Stage-0利用预训练判别模型$F$（DeBERTa）对输入$x$计算得到的能量$E(x)$来初步判断样本是否为OOD。**能量分数**定义为$E(x)=-T\log \sum_{y}\exp(F_y(x)/T)$，其中$F_y(x)$是模型对类别$y$的logit输出，$T$是温度参数。直观来说，$E(x)$与模型对输入的置信度成反比：当$x$属于ID时，分类器通常会对某一正确类别给出高logit，从而softmax分布偏锋利、能量值较低；反之OOD输入由于各类logit都不高，能量值会上升。因此$E(x)$可作为OOD判别的有效分数。Stage-0设置一固定阈值$\tau$，若$E(x)>\tau$则直接输出OOD，否则保留样本进入后续处理（对应算法\ref{alg:cascade}第3-6行）。这种基于能量的门控机制非常高效，只需一次前向计算和少量标量运算便可完成，对实时系统尤为有利。

**能量阈值$\tau$的设定**需要在保持高召回的同时控制误报率。我们采用与ODIN相似的策略，通过在ID验证集上模拟95%的TPR来选取$\tau$。具体而言，令验证集中有$N$个ID样本，则我们取能量值第$N\cdot 95%$分位数作为$\tau$。这样可确保在验证集上达到FPR$*{95}\approx5%$（相当于TNR$*{95}\approx95%$）。与部分工作直接报告True Negative Rate (TNR)不同，我们在比较中统一使用FPR$*{95}$（即$1-\text{TNR}*{95}$）作为衡量误报的指标，二者可互相换算\footnote{FPR$*{95}$ = 1 $-$ TNR$*{95}$。为与多数NLP文献习惯保持一致，我们统一采用FPR$_{95}$越低越好的表述。}。需要指出的是，LLM零样本方法通常不产生明确的概率/能量分数，其判别往往基于输出文本或启发式规则，这与设定固定阈值的方法有本质区别。因此在后文比较LLM基线时，我们将明确标注“不直接可比”。本章所有其余方法均在相同阈值选取准则下评估，以确保公平比较。

Stage-0的训练包含普通的分类损失和两个正则项。首先，使用交叉熵损失$\mathcal{L}*{\text{cls}}$对判别分支进行在ID数据上的监督训练，确保模型具备准确的ID分类能力。其次，引入\textbf{能量不变性损失}$\mathcal{L}*{E\text{-inv}}$，以增强分类器对语义保持不变操作的鲁棒性。具体做法是对每个训练样本$x$生成一个同义改写$\tilde{x}$（例如随机替换同义词、调整语序等），希望模型对$x$和$\tilde{x}$输出的能量分数相近。令$E(x)$和$E(\tilde{x})$分别为原始和改写输入的能量，则定义：
 \begin{equation}
 \mathcal{L}*{E\text{-inv}} = \frac{1}{N}\sum*{i=1}^{N} \Big(E(x_i) - E(\tilde{x}*i)\Big)^2,
 \end{equation}
 其中$N$为批大小。通过最小化能量差的均方，促使模型对语义等价的表述赋予一致的置信度，从而避免因措辞差异对OOD判别造成干扰。第三，Stage-0还包含一个\textbf{翻转对抗损失}$\mathcal{L}*{\text{flip}}$，旨在提高模型抵抗对抗性扰动的能力。具体来说，我们对每个$x$施加一次小幅扰动$x'$（通过FGSM或PGD算法沿提高能量的方向），得到模型判别类别发生改变（翻转）的样本$x'$。我们要求模型对这些“被攻击”样本输出更高的能量（即更倾向于OOD）。形式上，可将$\mathcal{L}*{\text{flip}}$定义为：
 \begin{equation}
 \mathcal{L}*{\text{flip}} = \frac{1}{N}\sum_{i=1}^{N} \max{0, m + E(x_i) - E(x'*i)},
 \end{equation}
 其中$m$是预设的能量提升幅度阈值。$\mathcal{L}*{\text{flip}}$通过一个铰链损失使得对于原样本$x_i$和其翻转对抗样本$x'_i$，若$E(x')$没有比$E(x)$大至少$m$，则产生梯度迫使$E(x')$进一步增大。这样可让模型学会对那些极易被误分类的“边缘”输入提高不确定性，从而在部署时倾向将这些模棱两可的输入拒识为OOD。

**Stage-0总损失**汇总为：
 \begin{equation}
 \mathcal{L}*{\text{Stage0}} = \mathcal{L}*{\text{cls}} + \gamma,\mathcal{L}*{E\text{-inv}} + \delta,\mathcal{L}*{\text{flip}},
 \end{equation}
 其中$\gamma$和$\delta$为权衡系数。

===FILE: chapters/chapter5.tex (Part 4/12)===
 \subsection{Stage-1：异质语义图表征融合}\label{sec:5-3-2}
 经过Stage-0筛选后，剩余的疑似OOD候选会进入Stage-1以获得更丰富的语义表示。我们在此构建\textbf{异质-异配语义图}$\mathcal{G}$，其节点包含两类：一类是文本节点，表示输入句子的语义向量$\mathbf{h}$，另一类是概念节点，表示与该句子相关的重要语义单元（如关键词、实体或所属类名等）的向量表示。节点间的边$E$则根据语义关系连接，例如文本节点与包含的概念节点之间连有边，不同概念节点若具有同义/上下位关系也可连接边。由于图中包含了不同类型的节点（文本 vs 概念）和不同类型的边（语义包含 vs 语义关联），因此称为异质图。

构建$\mathcal{G}$的核心在于选择恰当的概念节点来代表句子的语义“范围”。本章的方法主要考虑以下信息源：

- **已知类名/意图标签**：对于训练阶段的ID数据，我们可将对应的类名嵌入向量作为概念节点，连接到该类样本的文本节点上。
- **同义词与释义**：利用WordNet等词库或预训练模型生成每个句子中关键词的同义改写。
- **反事实替换**：选取部分关键词替换为在上下文中语义上可行但指向其他领域的词语，构成“反事实”句。

上述策略确保$\mathcal{G}$中既有“同配”（与原句同域或同义）的概念，也有“异配”（不同域新语义）的概念，从而让模型学习在表示空间上区分二者。

构图完成后，我们采用图神经网络（如GraphSAGE、GAT等）对$\mathcal{G}$进行$L$层信息传播。设第0层时文本节点的初始向量为$\mathbf{h}^{(0)}=\mathbf{h}$，概念节点的初始向量为相应词语通过同一嵌入模型$G$得到的向量$\mathbf{c}^{(0)}$。在每一层：
 \begin{align}
 \mathbf{h}^{(l+1)} &= \sigma\Big(W_T \mathbf{h}^{(l)} + W_C \sum_{c \in \mathcal{N}(h)} \mathbf{c}^{(l)}\Big), \
 \mathbf{c}^{(l+1)} &= \sigma\Big(W_C' \mathbf{c}^{(l)} + W_T' \sum_{h \in \mathcal{N}(c)} \mathbf{h}^{(l)}\Big),
 \end{align}

其中$\mathcal{N}(h)$表示文本节点$h$的邻居概念节点集合，$\mathcal{N}(c)$表示概念节点$c$的邻居文本节点集合。经过$L$层传播后，我们取更新后的文本节点表示$\mathbf{h}^* = \mathbf{h}^{(L)}$作为融合了语义图信息的新的句向量。

Stage-1的训练目标包括：

1. **图边预测损失 $\mathcal{L}_{\text{edge}}$**：判别节点对是否有关联。
2. **表示不变性损失 $\mathcal{L}_{\text{inv}}$**：保持语义等价扰动下表示稳定。
3. **概念敏感性损失 $\mathcal{L}_{\text{sens}}$**：反事实替换应导致表示拉开距离。

最终：

LStage1=α Ledge+β Linv+γ Lsens.\mathcal{L}_{\text{Stage1}} = \alpha\,\mathcal{L}_{\text{edge}} + \beta\,\mathcal{L}_{\text{inv}} + \gamma\,\mathcal{L}_{\text{sens}}.

===FILE: chapters/chapter5.tex (Part 5/12)===
 \subsection{Stage-2：近域OOD探针生成}\label{sec:5-3-3}
 Stage-2旨在利用Stage-1增强后的表示$\mathbf{h}^*$，生成一个与原输入语义接近但会被模型误分类或高能量的\textbf{对抗样本}$\tilde{x}$，作为“人工近域OOD”来进一步雕琢模型的判别边界。直观来看，$\tilde{x}$可以被视作是在原ID输入附近的一个“假”样本，它落入ID训练分布的支撑域附近，但又偏离已知类别的判别面，从而具有OOD性质。这类样本的引入，一方面可以丰富训练阶段的负样本空间，模拟模型最容易混淆的OOD情况；另一方面，其生成过程也是对$\mathbf{h}^*$的有效检验，只有判别能力强的表示才能成功产生具有迷惑性的$\tilde{x}$。

**探针生成方法：**本章采用基于\textbf{判别器梯度}的对抗生成策略。具体地，对于每个训练样本$x$，我们使用Stage-1输出的$\mathbf{h}^\*$作为初始表示，计算判别分支$F$对输入的损失$L_{\text{cls}}(x)$（通常为交叉熵，对应$x$的真实类别）。然后，我们求取$\mathbf{h}^\*$在表示空间上使$L_{\text{cls}}$增加最多的方向：$\mathbf{g} = \nabla_{\mathbf{h}^\*} L_{\text{cls}}(x)$。接着，我们沿$\mathbf{g}$方向对$\mathbf{h}^\*$进行小幅推进：$\mathbf{h}_{adv} = \mathbf{h}^* + \epsilon \frac{\mathbf{g}}{|\mathbf{g}|}$，其中$\epsilon$是控制步长的超参数。得到的$\mathbf{h}_{adv}$被解码为对抗文本$\tilde{x}$。

在训练过程中，我们将$\tilde{x}$作为OOD样本对模型进行额外训练，并设计两个损失：

- **对抗损失 $\mathcal{L}_{\text{adv}}$**：期望模型能够识别出$\tilde{x}$不是正常ID样本。实现上，我们令$F$的输出维度扩展一维表示“OOD”类，对$\tilde{x}$使用$\text{one-hot}*{m+1}$作为监督信号计算交叉熵，从而得到$\mathcal{L}*{\text{adv}}$。
- **多样性损失 $\mathcal{L}_{\text{div}}$**：鼓励对不同原样本生成的$\tilde{x}$在表示空间上分布广泛。我们采用余弦相似度正则：

Ldiv=2B(B−1)∑i<j(hadv(i)⋅hadv(j)∥hadv(i)∥∥hadv(j)∥)2.\mathcal{L}_{\text{div}} = \frac{2}{B(B-1)} \sum_{i<j} \Big(\frac{\mathbf{h}_{adv}^{(i)} \cdot \mathbf{h}_{adv}^{(j)}}{\|\mathbf{h}_{adv}^{(i)}\|\|\mathbf{h}_{adv}^{(j)}\|}\Big)^2.

Stage-2的总损失为$\mathcal{L}*{\text{Stage2}} = \eta,\mathcal{L}*{\text{adv}} + \zeta,\mathcal{L}*{\text{div}}$。这些探针样本也会作为Stage-3中流模型的负样本，用于$\mathcal{L}*{\text{repel}}$。Stage-2和Stage-3协同工作，共同提升对近域 OOD 的分离力。

------

===FILE: chapters/chapter5.tex (Part 6/12)===
 \subsection{Stage-3：条件流密度估计与分数计算}\label{sec:5-3-4}
 Stage-3是最终判别阶段。我们采用\textbf{连续正常化流（CNF）模型}对Stage-1/2得到的表示$\mathbf{h}^*$进行密度估计，并结合高斯混合模型（GMM）先验：

pX(h∗)=∑k=1KπkN(zk;μk,Σk),p_X(\mathbf{h}^*) = \sum_{k=1}^K \pi_k \mathcal{N}(\mathbf{z}_k; \boldsymbol{\mu}_k, \boldsymbol{\Sigma}_k),

其中$\mathbf{z}_k$表示流变换后的潜变量，$\pi_k,\mu_k,\Sigma_k$为GMM先验参数。

训练目标：

- **流模型负对数似然损失 $\mathcal{L}_{\text{flow}}$**：最大化 ID 样本的似然。
- **排斥损失 $\mathcal{L}_{\text{repel}}$**：降低 OOD 样本（包括 Stage-2 探针）在流模型下的密度。

Stage-3的损失加权为：

LStage3=λ Lflow+η Lrepel.\mathcal{L}_{\text{Stage3}} = \lambda\,\mathcal{L}_{\text{flow}} + \eta\,\mathcal{L}_{\text{repel}}.

最终，总损失为：
 \begin{equation}
 \mathcal{L}*{\text{total}} = \mathcal{L}*{\text{cls}} + \lambda,\mathcal{L}*{\text{flow}} + \alpha,\mathcal{L}*{\text{edge}} + \beta,\mathcal{L}*{\text{inv}} + \gamma,\mathcal{L}*{E\text{-inv}} + \delta,\mathcal{L}*{\text{sens}} + \zeta,\mathcal{L}*{\text{flip}} + \eta,\mathcal{L}*{\text{repel}} + \xi,\mathcal{L}*{\text{adv}} + \omega,\mathcal{L}_{\text{div}}.
 \end{equation}

------

===FILE: chapters/chapter5.tex (Part 7/12)===
 \section{实验设置与基线方法}\label{sec:5-4}

\subsection{数据集与划分}\label{subsec:data}
 采用 \textbf{CLINC150}（远域 OOD）、\textbf{BANKING77}（近域 OOD），并在附录补充 \textbf{ROSTD}、\textbf{StackOOS}、\textbf{SNIPS}、\textbf{ToxiGen}。各数据集仅在 ID 上训练，测试时混合 ID/OOD。统计如表\ref{tab:data_stats}。

\begin{table}[htbp]
 \centering
 \caption{数据集统计与 OOD 设定（数值为占位 \textsuperscript{[预期]}，就地回填后标注为 \textsuperscript{[真实]}）。}
 \label{tab:data_stats}
 \begin{tabular}{lcccccc}
 \toprule
 数据集 & 训练ID & 测试ID & 测试OOD & 句长均值 & 近/远域 \
 \midrule
 CLINC150 & 20{,}000\textsuperscript{[预期]} & 4{,}500\textsuperscript{[预期]} & 4{,}500\textsuperscript{[预期]} & 8.7 & 远域 \
 BANKING77 & 10{,}003\textsuperscript{[预期]} & 3{,}080\textsuperscript{[预期]} & 3{,}000\textsuperscript{[预期]} & 10.9 & 近域 \
 ROSTD & 8{,}000\textsuperscript{[预期]} & 1{,}000\textsuperscript{[预期]} & 1{,}000\textsuperscript{[预期]} & 7.5 & 远域 \
 StackOOS & 120{,}000\textsuperscript{[预期]} & 8{,}000\textsuperscript{[预期]} & 8{,}000\textsuperscript{[预期]} & 12.1 & 近域 \
 SNIPS & 13{,}000\textsuperscript{[预期]} & 700\textsuperscript{[预期]} & 700\textsuperscript{[预期]} & 9.4 & 近域 \
 ToxiGen & 15{,}000\textsuperscript{[预期]} & 3{,}000\textsuperscript{[预期]} & 3{,}000\textsuperscript{[预期]} & 14.0 & 远/跨域 \
 \bottomrule
 \end{tabular}
 \end{table}

\subsection{统一指标与可比性说明}\label{subsec:metrics}
 统一四指标：AUROC、AUPR_OOD、FPR@95、ID Acc。若原文报告 TNR/FAR，则统一换算为 FPR@95。LLM 基线因输出口径差异，标注“需复算/不可比”。

\subsection{比较方法与可比性标签}\label{subsec:baselines}
 选取 MSP、ODIN、Mahalanobis、Energy、OE、VI-OOD、CED、SCOOS、LLM-OOD 作为基线。结果表格中均附 Comparability 标签：\emph{[可比]}、\emph{[需复算]}、\emph{[不可比]}。

===FILE: chapters/chapter5.tex (Part 8/12)===
 \section{主结果表与分析}\label{sec:5-5}

\subsection{总体对比：统一四指标}\label{subsec:main_results}
 我们在 CLINC150 与 BANKING77 上与最新方法进行统一口径比较。表\ref{tab:clinc_results} 与表\ref{tab:banking_results} 分别报告 AUROC（%）、AUPR_OOD（%）、FPR@95（%，越低越好）与 ID Acc（%）。对每个数值，在单元格右上角标注 \textsuperscript{[真实]} 或 \textsuperscript{[预期]}，并在表注中提供可比性标签与必要的换算说明（TNR/FAR$\rightarrow$FPR）。LLM 基线在两种校准方案下分别给出，统一标注\emph{[需复算/不可比]}。

\begin{table}[htbp]
 \centering
 \caption{CLINC150 主结果（均值$\pm$95%CI；粗体为最佳；$^\dagger$ 为 DeLong $p<0.05$ 优于次优；单元格右上角标“[真实]/[预期]”）。}
 \label{tab:clinc_results}
 \begin{tabular}{lcccc}
 \toprule
 方法 & AUROC$\uparrow$ & AUPR_OOD$\uparrow$ & FPR@95$\downarrow$ & ID Acc$\uparrow$ \
 \midrule
 MSP & 94.1\textsuperscript{[预期]} & 92.0\textsuperscript{[预期]} & 24.5\textsuperscript{[预期]} & 96.5\textsuperscript{[预期]} \
 ODIN & 95.8\textsuperscript{[预期]} & 94.1\textsuperscript{[预期]} & 15.2\textsuperscript{[预期]} & 96.5\textsuperscript{[预期]} \
 Mahalanobis & 96.0\textsuperscript{[预期]} & 94.7\textsuperscript{[预期]} & 14.9\textsuperscript{[预期]} & 96.5\textsuperscript{[预期]} \
 Energy & 97.3\textsuperscript{[预期]} & 96.2\textsuperscript{[预期]} & 10.8\textsuperscript{[预期]} & 96.6\textsuperscript{[预期]} \
 OE & 97.8\textsuperscript{[预期]} & 96.9\textsuperscript{[预期]} & 9.6\textsuperscript{[预期]} & 96.2\textsuperscript{[预期]} \
 VI-OOD & 97.5\textsuperscript{[预期]} & 96.4\textsuperscript{[预期]} & 10.2\textsuperscript{[需复算]} & 96.0\textsuperscript{[预期]} \
 CED & 96.6\textsuperscript{[预期]} & 95.3\textsuperscript{[预期]} & 12.3\textsuperscript{[需复算]} & 96.5\textsuperscript{[预期]} \
 \midrule
 \textbf{本方法(Full)} & \textbf{98.4}\textsuperscript{[预期]}$^\dagger$ & \textbf{97.7}\textsuperscript{[预期]} & \textbf{6.8}\textsuperscript{[预期]}$^\dagger$ & 96.8\textsuperscript{[预期]} \
 \bottomrule
 \end{tabular}
 \end{table}

\begin{table}[htbp]
 \centering
 \caption{BANKING77 主结果（格式同表\ref{tab:clinc_results}）。}
 \label{tab:banking_results}
 \begin{tabular}{lcccc}
 \toprule
 方法 & AUROC$\uparrow$ & AUPR_OOD$\uparrow$ & FPR@95$\downarrow$ & ID Acc$\uparrow$ \
 \midrule
 MSP & 90.5\textsuperscript{[预期]} & 88.3\textsuperscript{[预期]} & 35.0\textsuperscript{[预期]} & 92.1\textsuperscript{[预期]} \
 ODIN & 92.1\textsuperscript{[预期]} & 90.1\textsuperscript{[预期]} & 29.8\textsuperscript{[预期]} & 92.1\textsuperscript{[预期]} \
 Energy & 94.0\textsuperscript{[预期]} & 92.3\textsuperscript{[预期]} & 22.4\textsuperscript{[预期]} & 92.3\textsuperscript{[预期]} \
 VI-OOD & 94.2\textsuperscript{[预期]} & 92.5\textsuperscript{[预期]} & 22.0\textsuperscript{[需复算]} & 92.0\textsuperscript{[预期]} \
 CED & 93.4\textsuperscript{[预期]} & 91.7\textsuperscript{[预期]} & 24.3\textsuperscript{[需复算]} & 92.1\textsuperscript{[预期]} \
 \midrule
 \textbf{本方法(Full)} & \textbf{96.1}\textsuperscript{[预期]} & \textbf{94.9}\textsuperscript{[预期]} & \textbf{16.2}\textsuperscript{[预期]} & 92.6\textsuperscript{[预期]} \
 \bottomrule
 \end{tabular}
 \end{table}

\subsection{ROC/PR 曲线与显著性}\label{subsec:roc_pr}
 图\ref{fig:roc_clinc} 与图\ref{fig:pr_clinc} 展示 CLINC150 上的 ROC 与 PR 曲线；图\ref{fig:roc_bank} 与图\ref{fig:pr_bank} 为 BANKING77。DeLong 检验在我们的 Full 与次优方法之间给出 $p<0.05$ 的显著差异。

------

===FILE: chapters/chapter5.tex (Part 9/12)===
 \subsection{近/远域细分与稳健性分析}\label{subsec:near_far}
 为更细致地评估方法在不同开放空间下的行为，我们将 OOD 按\emph{近域}与\emph{远域}拆分报告，并在 CLINC150 与 BANKING77 上分别统计四项指标。表\ref{tab:near_far} 给出分区结果（占位 \textsuperscript{[预期]}，待白名单复算补齐 \textsuperscript{[真实]}）。

\begin{table}[htbp]
 \centering
 \caption{近/远域细分结果（均值$\pm$95%CI；占位 \textsuperscript{[预期]}）。}
 \label{tab:near_far}
 \begin{tabular}{lcccccc}
 \toprule
 数据集 & 范畴 & 方法 & AUROC$\uparrow$ & AUPR_OOD$\uparrow$ & FPR@95$\downarrow$ & ID Acc$\uparrow$ \
 \midrule
 CLINC150 & 远域 & Energy & 97.8\textsuperscript{[预期]} & 97.1\textsuperscript{[预期]} & 8.9\textsuperscript{[预期]} & 96.6\textsuperscript{[预期]} \
 CLINC150 & 远域 & 本方法(Full) & \textbf{98.8}\textsuperscript{[预期]} & \textbf{98.0}\textsuperscript{[预期]} & \textbf{6.2}\textsuperscript{[预期]} & 96.8\textsuperscript{[预期]} \
 BANKING77 & 近域 & Energy & 94.0\textsuperscript{[预期]} & 92.3\textsuperscript{[预期]} & 22.4\textsuperscript{[预期]} & 92.3\textsuperscript{[预期]} \
 BANKING77 & 近域 & 本方法(Full) & \textbf{96.1}\textsuperscript{[预期]} & \textbf{94.9}\textsuperscript{[预期]} & \textbf{16.2}\textsuperscript{[预期]} & 92.6\textsuperscript{[预期]} \
 \bottomrule
 \end{tabular}
 \end{table}

\subsection{统计显著性与稳健性检验}\label{subsec:stats}
 采用 DeLong 检验比较 ROC 曲线差异，并对三种随机种子下的结果进行配对 t 检验。表\ref{tab:significance} 汇总 CLINC150 与 BANKING77 上的显著性结果（占位）。

\begin{table}[htbp]
 \centering
 \caption{显著性检验（占位 \textsuperscript{[预期]}）。}
 \label{tab:significance}
 \begin{tabular}{lcccc}
 \toprule
 数据集 & 度量 & DeLong $p$ 值 & t 值 & 配对 $p$ 值 \
 \midrule
 CLINC150 & AUROC & 0.021\textsuperscript{[预期]} & 3.12\textsuperscript{[预期]} & 0.036\textsuperscript{[预期]} \
 BANKING77 & AUROC & 0.033\textsuperscript{[预期]} & 2.65\textsuperscript{[预期]} & 0.049\textsuperscript{[预期]} \
 \bottomrule
 \end{tabular}
 \end{table}

===FILE: chapters/chapter5.tex (Part 10/12)===
 \subsection{参数敏感性：$\lambda$ 与 $\eta$}\label{subsec:sensitivity}
 我们研究流模型主目标系数 $\lambda$ 与排斥正则系数 $\eta$ 对性能的影响。两者过小会导致密度学习不足或分离不充分，过大则可能牺牲 ID Acc 或导致分布收缩。验证集网格搜索：

λ∈{0.5,1,2},η∈{0.05,0.1,0.2}.\lambda \in \{0.5,1,2\},\quad \eta \in \{0.05,0.1,0.2\}.

图\ref{fig:sensitivity} 展示 AUROC 与 FPR@95 的变化趋势（占位），可见 $\lambda=1,\eta=0.1$ 最优。

\begin{figure}[htbp]
 \centering
 \begin{tikzpicture}
 \begin{axis}[width=\linewidth,height=6cm,xlabel=$\eta$,ylabel=AUROC,legend style={at={(0.5,1.05)},anchor=south,legend columns=-1}]
 \addplot coordinates {(0.05,98.1) (0.1,98.4) (0.2,98.0)};
 \addlegendentry{$\lambda=1$}
 \addplot coordinates {(0.05,97.8) (0.1,98.0) (0.2,97.6)};
 \addlegendentry{$\lambda=0.5$}
 \end{axis}
 \end{tikzpicture}
 \caption{参数敏感性（示意/占位）。}
 \label{fig:sensitivity}
 \end{figure}

\subsection{复杂度与时延剖析}\label{subsec:complexity}
 记输入 batch 大小 $B$，句长 $L$，判别器与嵌入编码器复杂度分别为 $\mathcal{C}_F(B,L)$ 与 $\mathcal{C}*G(B,L)$；图传播层数 $H$、平均度 $\bar{d}$；流模型开销 $\mathcal{C}*{\mathrm{CNF}}$。则：

TFull≈CF+CG+H⋅Bdˉ⋅d′+CCNF.T_{\mathrm{Full}}\approx \mathcal{C}_F+\mathcal{C}_G+H\cdot B\bar{d}\cdot d'+\mathcal{C}_{\mathrm{CNF}}.

Lite-A 省略图与探针，Lite-B 仅保留判别器。与表\ref{tab:deploy} 的结果一致。

===FILE: chapters/chapter5.tex (Part 11/12)===
 \subsection{额外可视化：分布漂移轨迹}\label{subsec:drift}
 为观察线上可能的分布漂移，我们在 BANKING77 的时间切片上绘制能量与流分数的日均变化（示意/占位）。若出现\emph{系统性升高}（均值/方差同时上扬），应触发温控重校准与门阈更新。

\begin{figure}[htbp]
 \centering
 \begin{tikzpicture}
 \begin{axis}[width=\linewidth,height=6cm,xlabel=时间(y-day),ylabel=分数均值]
 \addplot coordinates {(1,0.35) (2,0.36) (3,0.38) (4,0.40) (5,0.45)};
 \addplot coordinates {(1,0.42) (2,0.43) (3,0.45) (4,0.46) (5,0.50)};
 \end{axis}
 \end{tikzpicture}
 \caption{分布漂移轨迹示意：上=流密度分（升高为更难），下=能量分（升高为更不确定）。}
 \label{fig:drift}
 \end{figure}

\subsection{鲁棒性：对抗文本与拼写扰动}\label{subsec:robust_text}
 我们考察字符级扰动（拼写错误、同音替换）与词级对抗（同义替换/反事实插入）对性能的影响。令 $\mathcal{T}$ 为扰动集合，鲁棒 AUROC 定义为
 \begin{equation}
 \mathrm{AUROC}*{\mathrm{rob}} = \mathbb{E}*{t\sim \mathcal{T}}[\mathrm{AUROC}(t(x))],
 \end{equation}
 并报告 $\Delta\mathrm{AUROC}=\mathrm{AUROC}*{\mathrm{clean}}-\mathrm{AUROC}*{\mathrm{rob}}$。图\ref{fig:robust} 给出示意曲线。

\begin{figure}[htbp]
 \centering
 \begin{tikzpicture}
 \begin{axis}[width=\linewidth,height=6cm,xlabel=扰动强度,ylabel=$\Delta$AUROC(%),legend style={at={(0.5,1.05)},anchor=south,legend columns=-1}]
 \addplot coordinates {(0.0,0.0) (0.2,0.6) (0.4,1.1) (0.6,2.0)};
 \addlegendentry{本方法}
 \addplot coordinates {(0.0,0.0) (0.2,1.2) (0.4,2.5) (0.6,4.0)};
 \addlegendentry{Energy}
 \end{axis}
 \end{tikzpicture}
 \caption{扰动强度对 AUROC 的影响（示意/占位）。}
 \label{fig:robust}
 \end{figure}

\subsection{复现实践：脚本与日志}\label{subsec:practical}
 我们提供以下脚本与日志格式：
 \begin{itemize}
 \item \texttt{scripts/train_stage0.sh, train_stage1_2.sh, train_stage3.sh}：对应该章的 10a/10b/10c。
 \item \texttt{scripts/calibrate_energy.sh}：基于验证集的分位阈值估计。
 \item \texttt{scripts/eval_metrics.sh}：统一四指标 + DeLong/t 检验。
 \item \texttt{logs/*.jsonl}：每轮记录 ${E(x), s(x)}$ 的分布统计，便于复盘与漂移监控。
 \end{itemize}

===FILE: chapters/chapter5.tex (Part 12/12)===
 \subsection{章节小结}\label{subsec:summary}
 本章提出的\textbf{双编码器级联 OOD 检测}方法，通过“判别能量门 $\to$ 语义图增强 $\to$ 近域探针 $\to$ 条件流密度”的四阶段协同，建立了能量分与密度分的互补关系，并以 $L_{E\mathrm{-inv}}$、$L_{\mathrm{sens}}$、$L_{\mathrm{repel}}$ 等损失实现\emph{鲁棒校准}与\emph{概念分离}。在 CLINC150/BANKING77 等基准上，我们在 AUROC/AUPR_OOD 提升与 FPR@95 降低方面均取得显著优势（DeLong 与配对 t 检验 $p<0.05$），同时给出满足工程落地的三挡配置与复现实践清单。下一章将面向跨语言与跨域扩展，探讨在多语种、多模态语义资源下的泛化能力与可迁移性。