\chapter{第五章：CP-ABR++——级联、高效、鲁棒且可解释的文本OOD检测}\label{chap:chapter5}

\section{引言}\label{introduction}
开放世界文本 \textsc{OOD}（Out-of-Distribution，分布外）检测面临着近域 \textsc{OOD} 和远域 \textsc{OOD} 等多重挑战。其中，**近域 OOD**（Near-OOD）样本在语义上与已知类别非常接近，往往位于已知类流形的边缘或交叠区域，极易导致模型混淆；相比之下，**远域 OOD**（Far-OOD）样本与任何已知类别均明显不同，检测相对容易~\cite{hendrycks17baseline}。现有方法在近域 OOD 上通常失效，表现为分类器对这些样本过度自信、拒识率低下，同时已知类判别边界在高维表示空间中出现**流形纠缠**~\cite{yang2021openset}——OOD 样本嵌入在 ID 类簇内部或附近，难以分离。这种问题在文本场景尤为突出，因为短文本的**语义偏移**与**协变量偏移**常交织：模型可能依据浅层词频特征产生错误置信度，而忽视深层语义差异。

为了解决上述难题，本文引入了**异配性（heterophily）**概念并将其作为文本 OOD 检测的关键视角。在我们构建的“用户话语—语义概念—类别”语义图中，可以观察到相邻节点往往来自不同的语义簇或类别（例如，一句话包含“账单争议”这一概念，可能与包含“欺诈交易”概念的句子通过共享概念节点相连，但它们的意图类别却不同）。这种**异质且异配**的图结构正是文本 OOD **近域混淆**在语义空间中的体现：语义上相似的内容可能对应不同的意图类别，导致同质假设的方法（假设邻居同类，同配性）在此退化。针对这一问题，我们明确采用**异质—异配语义图**来建模文本语义关联，并引入对异配连接友好的信息聚合策略，以**缓解流形纠缠**、提高近域 OOD 的可分性。

基于上述洞察，我们提出了一个级联多模块的方法框架 **CP-ABR++**，旨在实现高效、鲁棒且可解释的文本 OOD 检测。其核心思想是在推理过程中逐步筛选和增强信息：首先以**级联筛选**快速滤除明显的 OOD 提高效率，然后利用**语义图结构**增强对模棱两可样本的表示，再通过**主动探针**扩展决策边界未见区域，结合**条件流模型**进行可靠的分布密度估计以计算异常分数，最后生成**证据链式解释**提升结果的可解释性。具体来说，CP-ABR++ 包含以下创新模块：
\begin{itemize}
    \item 提出级联式能量门（Stage-0），通过预训练分类器的\textbf{能量分数}快速判断明显 OOD 样本，实现早期筛选以降低后续模块的计算负担。
    \item 构建异质—异配的\textbf{语义因果图}（Stage-1），将用户话语、概念节点与类别节点连接成图结构，并采用兼容异配性的 GNN 进行语义聚合，在结构化语义空间中缓解近域 OOD 的流形混叠。我们引入**概念干预**（do-operator）来评估概念对异常分数的影响，并据此优化模型的稳定性。
    \item 设计\textbf{多样性自适应探针}机制（Stage-2），针对模型判别边缘的高不确定样本，生成多样化的候选探针（包括基于概念开关的反事实样本），通过对抗训练扩大已知决策边界，从而降低未知区域的误检率。
    \item 构建\textbf{多模态条件流}检测器（Stage-3），使用条件归一化流（CNF）结合高斯混合先验，对 ID 数据的复杂分布进行建模。我们加入\textbf{排斥损失}确保生成探针在流空间中的低密度，以及\textbf{因果敏感度正则}提高模型对无关概念扰动的稳健性，从而输出稳定可靠的异常分数。
    \item 集成\textbf{证据链解释}模块（Stage-4），综合语义图连通性和流空间异常线索，采用模板驱动的 LLM 生成检测决策的自然语言解释，增强结果的可审查性和可信度。
    \item 在保证性能的同时，我们遵循奥卡姆剃刀原则，对模型进行模块化裁剪：本文报告了两种\textbf{轻量配置}（Lite-A/B），分别裁剪 Stage-2 和 Stage-1+2，以验证各模块的独立增益并提供资源受限场景下的实用备选。这确保我们的性能提升源自核心创新，而非简单堆叠模型复杂度。
\end{itemize}

综上，CP-ABR++ 以端到端可微的核心架构（编码器+GNN+流模型）结合外部知识（LLM 构图与解释）的范式，实现了文本 OOD 的高效筛查、近域鲁棒检测以及结果可解释。在下文中，我们将详细介绍该方法的组成部分及其实验表现。

\section{模型概述}\label{cpabr_overview}
\subsection{相关定义与术语}
在介绍模型细节之前，我们先 formalize 一些基本概念和符号。令 $\mathcal{D}_{\text{ID}}$ 表示训练期可获取的 ID（分布内）语料，涵盖若干预定义类别；$\mathcal{D}_{\text{OOD}}$ 表示开放世界中可能出现的 OOD 样本集合（类别未知，不参与训练）。模型在测试时需要判定任意输入 $x$ 属于 $\mathcal{D}_{\text{ID}}$ 的某一已知类，或判为 OOD。对于 OOD，我们进一步区分：
**近域 OOD**指语义上与某些 ID 类别接近、容易混淆的样本；
**远域 OOD**则指与所有已知类别均明显不同的样本。

我们采用一个预训练分类器 $f(x)$ 提供每个输入在各已知类别上的 logit 分数 $f_k(x)$。由此得到的\textbf{能量分数}定义为：
\begin{equation}
E(x) = -\,T \log \sum_{k} \exp\{f_k(x)/T\},
\label{eq:energy}
\end{equation}
其中 $T$ 是温度缩放参数~\cite{liu2020energy}。$E(x)$ 值越高表示模型对 $x$ 趋向于不属于任何已知类（即 softmax 概率分布更均匀）。基于 $E(x)$，我们进一步定义\textbf{异常分数} $s(x)$ 来量化 $x$ 为 OOD 的倾向，其具体形式将在 Stage-3 中给出（本质上 $s(x)$ 与 $E(x)$ 正相关，但经过条件密度估计校准）。

此外，我们构建一个\textbf{异质—异配语义图} $G=(V, E, W)$，其中 $V$ 包含不同类型的节点（如用户话语、语义概念、意图类别），$E$ 为多种关系的边集，$W$ 表示边权或关系类型。图的**异配率**可衡量为：对于具有类别标签的节点，其邻居中与其不同类的节点所占比例（相对同类邻居）。$G$ 的异配性越高，表示连接更多发生在不同类别/语义簇之间。

\paragraph{因果启发的 SCM.} 
为引入可干预的因果视角，我们假设存在一组二元\textbf{概念开关} $C=\{C_j\}$ 影响着话语 $X$ 的产生，进而影响模型判决 $\hat{Y}$。例如 $C_j$ 可以表示“fraud（欺诈）”这一概念是否出现。我们采用简洁的链式结构：
\begin{equation}
C_j \rightarrow X \rightarrow Z \rightarrow \hat{Y}\,,
\label{eq:scm-chain}
\end{equation}
其中 $Z$ 表示中间语义表示（如编码器与 GNN 的输出）。对概念 $C_j$ 的干预用 $do(C_j=1/0)$ 表示。需要说明的是，我们将上述因果结构作为一种启发用于模型设计与分析：通过对概念开关施加 $do$ 操作并观测异常分数的变化，我们可以评估该概念对 OOD 判定的影响（详见 Stage-2 与 Stage-3）。但本文并不声称进行严格的因果推断，而是将其视为一种证据化验证手段，用于提升模型的稳健性和可解释性。

\subsection{总体框架设计}
如图~\ref{fig:intuitive_space} 所示，我们以二维投影示意 CP-ABR++ 的工作原理。左图展示了传统方法在表示空间中的分布：彩色点表示各已知意图类别的样本，叉号表示 OOD 样本。其中一些近域 OOD 样本（红叉）明显嵌入在某些已知类簇周围甚至内部，导致模型难以及时分辨。而右图为本章方法在相同数据上的效果：通过引入语义图和条件流模型，OOD 样本（特别是近域 OOD）被有效地从 ID 类簇中“挤出”，在高维空间形成与已知类清晰分离的分布，从而降低误检率。这种改进源于两个方面：一方面，语义图聚合增强了 ID 样本的类内凝聚力，并通过异配连接削弱了跨类的错误关联；另一方面，条件流模型提供了更精细的概率刻画，使得对异常的判别更加可靠。

\begin{figure}[htp]
\centering
\includegraphics[width=0.9\columnwidth]{figures/chap5/intuitive_space.pdf}
\caption{直观对比：传统方法 vs. CP-ABR++ 的表示分布。左图：某基线模型在 CLINC150 数据集上的 t-SNE 可视化，近域 OOD 样本（红叉）散布于多个 ID 类簇（圆点）周围，部分出现混杂；右图：CP-ABR++ 将 OOD 样本有效地推离已知类流形，各类别圆点分布清晰且与 OOD 样本分离。}
\label{fig:intuitive_space}
\end{figure}

整体而言，CP-ABR++ 采用**级联多阶段架构**：模型按顺序执行 Stage-0 至 Stage-4，每一阶段各司其职，共同完成从粗筛到精判再到解释的闭环。图~\ref{fig:architecture} 展示了该架构的组成模块和信息流程。首先，输入文本经过编码器提取初步特征表示（记作 $\mathbf{h}_0$）并送入预训练分类器计算能量分数 $E(x)$（Stage-0），由能量门进行快速筛选；然后，对于未被滤除的样本，构建对应的异质语义图并通过 GNN 获得富语义的图表示 $\mathbf{h}_*$（Stage-1）；接着在训练阶段，Stage-2 针对高不确定样本生成额外的探针样本用于学习，强化模型对 OOD 的感知；而在推理阶段，模型直接进入 Stage-3，基于图表示 $\mathbf{h}_*$ 通过条件归一化流估计输入属于 ID 分布的概率密度，并计算异常分数 $s(x)=-\log p_X(x|\mathbf{h}_*)$；最后，Stage-4 综合图上的连通性和流空间线索给出链式解释。与现有方法不同的是，我们将 LLM 技术融入到了构图和解释步骤中（作为外部辅助模块），而核心的编码器、GNN 和流模型则是端到端联合优化的。在实际部署中，Stage-2 仅在训练期启用，Stage-4 可按需启用解释功能，从而实现“核心端到端 + 外部知识辅助”的模块化架构。

\begin{figure*}[htp]
\centering
\includegraphics[width=0.95\textwidth]{figures/chap5/architecture.pdf}
\caption{CP-ABR++ 模型总体架构示意图。不同模块的数据流以颜色区分：蓝色箭头表示原始输入 $X$ 的处理流程，红色箭头表示概念 $C$ 等语义信息的注入流程。系统按照 Stage-0 到 Stage-4 级联执行：Stage-0 使用能量门对输入进行快速筛查；Stage-1 构建异质-异配语义图并计算图表示；Stage-2（训练期）生成自适应探针强化决策边界；Stage-3 利用条件归一化流对输入进行条件密度估计并输出异常分数；Stage-4 生成包含语义证据和流证据的链式解释。}
\label{fig:architecture}
\end{figure*}

\subsection{总体模型}
图~\ref{fig:architecture} 给出了 CP-ABR++ 框架的组成部分和信息流。下面我们按阶段概要描述各模块功能：

- \textbf{Stage-0 级联能量门：}输入经过 BERT-base 编码器和预训练分类器 $f(x)$ 计算能量分数 $E(x)$（式~\eqref{eq:energy}）。模型设置阈值 $\tau_E$（根据 ID 验证集上 $95\%$ 分位点选取）用于速判 OOD。具体而言，如果 $E(x) > \tau_E$，则直接将 $x$ 判为 OOD 并终止后续计算；若 $E(x) \ll \tau_E$（能量极低，模型极为自信）则直接输出 ID 判决；其余样本进入下一阶段处理。通过 Stage-0 筛选，大约 $30\%$--$50\%$ 的明显 OOD 样本可被快速过滤，降低了后续模块的负载且几乎不影响整体召回率。在我们的实现中，$\tau_E$ 取使训练集 ID 样本通过率约 $95\%$ 的值，从而保证对 ID 准确率的影响可忽略。作为效率优化主轴，Stage-0 也支持部署时的极简模式：仅结合 Stage-3 使用（即 Lite-B 配置），以最低代价完成基本的 OOD 检测。

- \textbf{Stage-1 异质—异配语义因果图 (HHG) 构建与编码：}对于通过 Stage-0 的输入，CP-ABR++ 构建其对应的**异质—异配语义图**。该图包含三类节点：(\romannumeral1) 用户话语节点，(\romannumeral2) 语义概念节点，(\romannumeral3) 意图类别节点；边关系包括“话语包含概念”、“概念关联类别”、“话语属于类别”（仅训练期已知类）等多种类型。由于节点类型和关系的多样性，所构建图为异质图；更重要的是，由于一个概念往往出现在不同类别的话语中，图中相邻节点经常属于不同类别或语义簇，呈现高度的异配性。例如，概念节点“付款（payment）”可能连接到意图类别“账单查询”下的样本，同时也连接到“欺诈举报”类的样本，从而使这两类话语节点在图中变得邻近。为在这种非同配图上进行有效的信息传播，我们设计了一种**异配友好型** GNN。具体而言，引入邻居兼容系数 $\kappa_{ij}\in\{+1,-1\}$ 表示节点 $i$ 与邻居 $j$ 在类别标签上的异同（同类为 +1，异类为 -1；对于概念节点等无类节点，可根据其主要关联类别或预训练模型判断赋值），并在消息传递时对异类邻居给予更高权重。GNN 第 $\ell$ 层中节点 $i$ 的表示更新为：
\begin{equation}
\mathbf{h}_i^{(\ell+1)} = \sigma\!\Big(
W_0^{(\ell)}\mathbf{h}_i^{(\ell)}
+ \sum_{r\in\mathcal{R}}\sum_{j\in\mathcal{N}_i^r}
\alpha_{ij}^{(r)}\, W_r^{(\ell)} \mathbf{h}_j^{(\ell)}
\Big),
\quad 
\alpha_{ij}^{(r)} \propto \exp\!\big(\phi_r(i,j)\cdot \kappa_{ij}\big),
\label{eq:hhg-message}
\end{equation}
其中 $\mathcal{N}_i^r$ 表示节点 $i$ 在关系类型 $r$ 下的邻居集，$W_0^{(\ell)}$ 和 $W_r^{(\ell)}$ 为可学习的投影矩阵，$\sigma$ 是激活函数，$\phi_r(i,j)$ 表示基于关系类型和节点特征的注意力打分。通过上述机制，当节点 $i$ 和 $j$ 属于异类（$\kappa_{ij}=-1$）时，其连接在注意力权重上将获得相对提升，以缓解传统同配 GNN 在异配图上的“过平滑”问题。需要说明的是，在测试时 OOD 输入的类别未知，我们仍使用训练阶段学到的 GNN 权重来聚合其与概念节点的关系，因此 $\kappa_{ij}$ 的作用主要体现在训练过程中，引导模型更多关注“跨类别”的语义关联信号。

语义图的构建借助大语言模型（LLM）提供外部知识和假设关联。具体而言，对于每个输入话语，我们使用 LLM（如 GPT-4 或 LLaMA-2）提取其中蕴含的**语义概念**（关键词、领域实体等），将这些概念作为图中的概念节点；同时，LLM 基于自身知识判断这些概念与已知意图类别之间的关联强度。例如，LLM 可能判断“付款”概念与“账单查询”类别关联更紧密。我们据此为概念节点与类别节点添加加权边。为减少 LLM 幻觉和偏差，我们设置了**一致性自检**机制：通过追问验证每条生成边的合理性，或将 LLM 推断与简单分类器结果比对，对于置信度低或存在矛盾的边，降低其权重或将其移除。此外，我们限定每个输入最多引入 $K$ 个概念节点及其相关边（如 $K=5$），优先选择得分最高的语义关系，以控制图规模和噪声。

构图完成后，我们对得到的图应用两层 Relational-GCN（结合公式~\eqref{eq:hhg-message} 的异配注意力）计算节点表示。取输出层中对应输入话语节点的嵌入 $\mathbf{h}_*$ 作为 $x$ 的图增强表示，用于后续判断。借助图谱语义，$\mathbf{h}_*$ 相比原始编码器输出包含了更丰富的上下文信息，可辅助识别那些表面与某已知类相似但语义本质偏离的 OOD 输入。我们的消融实验显示，去除 Stage-1 会使近域 OOD 检测性能显著下降（表~\ref{tab:ablation}），这证明了结构化语义信息对于缓解近域混淆的价值。当然，在极端资源受限场景，Stage-1 亦可按需裁剪（对应 Lite-B 配置，仅以编码器表示输入 Stage-3），详细的性能影响可参见后文讨论。

- \textbf{Stage-2 多样性自适应探针：}为了进一步提升模型对未知空间的感知能力，我们在训练过程中引入自适应探针生成机制。直观而言，我们希望主动生成并学习一些“模型尚无法正确识别”的样本，以扩大判别边界。探针样本应满足两个要求：(\romannumeral1) 足够“难”，处于模型当前判决的不确定区域；(\romannumeral2) 足够“广”，覆盖多种潜在 OOD 情形。为此，我们首先在每轮训练中从 ID 训练数据中筛选出当前模型不确定性最高的一批样本（例如 softmax 熵最高的 $m$ 个样本，或基于马氏距离判断处于类中心边缘的样本），记作集合 $\mathcal{U}$。然后针对每个 $x \in \mathcal{U}$，使用生成模型（如小型扩散模型或 GPT-3.5）对其进行一定幅度的扰动或改写，生成若干候选\textbf{探针样本}（记作集合 $\mathcal{P}$）。具体生成策略包括：对 $x$ 进行同义替换、增删细节等微调，使其语义略偏离原有类别；或者让 LLM 根据 $x$ 所属类别的相反语义来生成一个明显不属于该类别的新句子。在我们的实现中，还利用 Stage-1 图信息进行**反事实探针**：针对 $x$ 所涉及的某个重要概念 $C_j$，构造 $x$ 的一个变体 $x^{cf}_j$，强制该概念出现或移除（即施加 $do(C_j=1)$ 或 $do(C_j=0)$），以模拟关键语义要素的有无对判别的影响。这些生成的探针样本经人工检查通常不属于任何已知类别，即应被模型判为 OOD。

有了探针集合 $\mathcal{P}$，我们在训练时将其作为“伪 OOD”样本加入模型优化，目标是提升模型对这些样本的异常判别能力。具体地，我们为探针构造了两类损失：一是\textbf{对抗损失} $\mathcal{L}_{adv}$，使模型倾向于将探针判为 OOD（即 $s(x^{probe})$ 尽可能高）；二是\textbf{多样性损失} $\mathcal{L}_{div}$，鼓励生成的探针在语义上尽量多样而非局限于某种固定模式。为简洁起见，这两项损失可组合表示为 $\mathcal{L}_{\text{probe}} = \mathcal{L}_{adv} - \eta \mathcal{L}_{div}$（其中 $\eta$ 为权衡系数）。此外，对于每对原始样本与其反事实探针 $(x,\;x^{cf}_j) \in \mathcal{P}$，我们增加\textbf{反事实一致性约束}：
\begin{equation}
\mathcal{L}_{cf} = \frac{1}{|\mathcal{P}_{cf}|}\sum_{(x,\,x^{cf}_j)\in\mathcal{P}_{cf}} \Big|\, s(x)\;-\;s(x^{cf}_j) \,\Big|\,,
\label{eq:cf-consistency}
\end{equation}
其中 $\mathcal{P}_{cf}$ 表示所有反事实探针对。$\mathcal{L}_{cf}$ 惩罚模型对原始样本与其反事实版本给出显著不同的异常分数，从而提高对非关键概念变化的鲁棒性（上式中我们默认 $\Delta_j=0$，即假设移除单一概念不应极大地改变判别结果）。

通过联合优化上述损失（详见总损失函数），Stage-2 在训练期有效扩展了模型的决策边界，对近域 OOD 性能有所提升（移除 Stage-2 导致 AUROC 下降，见表~\ref{tab:ablation}）。需要强调的是，Stage-2 仅在训练阶段启用，对推理速度没有影响。在实际应用中，如果训练资源有限或希望简化流程，可以关闭 Stage-2（对应 Lite-A 配置），此时模型性能略有折损但仍保持主要功能。

- \textbf{Stage-3 多模态条件流检测：}我们采用**条件归一化流**（Conditional Normalizing Flow, CNF）作为 OOD 判别的核心评分模块。相比基于 softmax 概率或能量的简单方法，流模型能够刻画已知分布的复杂形状，对近域 OOD 更加敏感。具体而言，我们训练一个条件流模型 $f_\theta(\cdot \mid \mathbf{h}_*)$ 将输入 $x$ 从原空间映射到潜空间表示 $z = f_\theta(x \mid \mathbf{h}_*)$，同时保证该映射为可逆可微。根据改变变量公式，$x$ 属于 ID 数据分布的对数密度为：
\begin{equation}
\log p_X(x \mid \mathbf{h}_*) = \log p_Z\!\big( z = f_\theta(x\mid \mathbf{h}_*) \big) + \log \Big| \det \frac{\partial f_\theta}{\partial x} \Big|\!,
\label{eq:cnf}
\end{equation}
其中 $p_Z(\cdot)$ 是潜空间 $z$ 上的先验密度。我们采用高斯混合模型（GMM）作为先验，以捕捉 ID 数据潜表示可能呈现的多峰特性：$p_Z(z) = \sum_{c=1}^K \pi_c\, \mathcal{N}(z;\mu_c, \Sigma_c)$（$K$ 取为 ID 类别数或由验证集调优）。相比单高斯先验，混合模型能更好地拟合各类别或语义簇的嵌入分布差异，避免因单峰假设导致的 OOD 漏检。利用式~\eqref{eq:cnf}，我们将输入的**异常分数**定义为
\[
s(x) = -\,\log p_X(x \mid \mathbf{h}_*)\,,
\] 
即 $x$ 在流模型下属于 ID 分布的负对数概率。$s(x)$ 值越大，表示 $x$ 越不像来自训练分布，因而越可能是 OOD。

为训练流模型，我们需要确保：ID 样本经 $f_\theta$ 映射后的潜变量 $z$ 符合先验分布（最大化对数似然 $\log p_X$），而 OOD 探针样本应被赋予尽可能低的密度。为此，我们在训练目标中加入\textbf{排斥损失}：
\begin{equation}
\mathcal{L}_{\text{repel}} = -\,\mathbb{E}_{x^{probe}\in \mathcal{P}} \log p_X\!\big(x^{probe} \mid \mathbf{h}_*^{probe}\big)\,,
\label{eq:repel}
\end{equation}
即降低探针样本在流模型下的概率密度，以将它们“排斥”出已知分布区域。此外，我们保留分类器的交叉熵损失 $\mathcal{L}_{\text{ID-cls}}$，确保编码器和 GNN 仍维持对 ID 类的判别能力。最终，总损失函数形式为：
\begin{equation}
\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{ID-cls}} + \alpha\,\mathcal{L}_{\text{flow}} + \beta\,\mathcal{L}_{\text{repel}} + \gamma\,\mathcal{L}_{cf} + \zeta\,\mathcal{L}_{inv}\,,
\label{eq:total-loss}
\end{equation}
其中 $\mathcal{L}_{\text{flow}} = -\,\mathbb{E}_{x\in \mathcal{D}_{ID}} \log p_X(x\mid \mathbf{h}_*)$ 表示 ID 样本的流对数似然损失，$\mathcal{L}_{cf}$ 为式~\eqref{eq:cf-consistency} 定义的反事实一致性约束，$\mathcal{L}_{inv}$ 则是**因果不变性正则**，度量模型对各概念干预的敏感度：
\begin{equation}
I_j = \mathbb{E}\big[\,s(x)\mid do(C_j=1)\,\big] \;-\; \mathbb{E}\big[\,s(x)\mid do(C_j=0)\,\big]\,,
\qquad 
\mathcal{L}_{inv}=\sum\nolimits_j \big| I_j \big|\,,
\label{eq:causal-sensitivity}
\end{equation}
即概念 $C_j$ 从缺失到出现（或反向）的干预对异常分数的平均影响量。通过最小化 $\mathcal{L}_{inv}$，我们希望模型降低对单一概念的过度依赖，从而提高对无关扰动的稳健性。训练中我们通常取 $\alpha=1$ 平衡检测与分类主任务，而将 $\beta,\gamma,\zeta$ 设为较小值（如 $0.1$）用于正则。

需要指出的是，Stage-3 中流模型与编码器、GNN 是**联合训练**的。不同于一些两阶段方案，我们从头到尾以端到端方式优化文本表示、图关系和密度模型，使各部分协同提升性能。在推理阶段，Stage-3 使用学到的密度模型计算 $s(x)$ 并与阈值比较给出最终判定。我们一般根据验证集上当 TPR 达到 $95\%$ 时的 $s(x)$ 设定阈值，以控制 FPR。本章稍后将通过消融实验验证 Stage-3 的有效性，说明使用条件流和 GMM 先验相较简单能量法的优越性。

- \textbf{Stage-4 证据链解释生成：}CP-ABR++ 的最后一环旨在为检测结果提供可追溯的解释。我们从模型内部提取两类**证据**：(1) \textbf{图证据：}如果输入 $x$ 被判为 OOD，我们检查其对应的语义子图结构，例如 $x$ 是否缺乏与某已知类别节点的紧密连接、其概念节点是否主要连接到了多个不同类别（指示语义上的不确定性），抑或图中是否存在将 $x$ 所属子图与其余部分隔离的“桥接边”被剪除等。这类结构信息可以支持 $x$ 属于未知类的判断。相反，若 $x$ 判为 ID，则通常可在图中找到其与某类别节点之间的明确连接路径，作为归属该类的证据。(2) \textbf{流证据：}我们同时检查 Stage-3 流模型的输出，如 $x$ 的潜变量 $z$ 在先验 GMM 中所属的分量，以及 $z$ 到各分量均值的马氏距离。如果 $x$ 为 OOD，往往会出现 $z$ 远离所有混合分量中心、或落在两个已知分量之间的低密度区域等现象；若为 ID，则 $z$ 应贴近某一高密度分量。以上证据都可转化为人类可理解的语言描述。

在提取证据后，我们采用模板填充和 LLM 概括相结合的策略生成自然语言解释。首先，根据判定结果选择对应的模板骨架，例如 OOD 判定的模板可能是：“输入涉及的 $\langle$\texttt{概念列表}$\rangle$ 在任何已知意图中都未曾同时出现，且其表示与所有已知类别分布均存在显著距离，因此判定其为未知意图。” 然后将从模型得到的具体证据（如检测到的关键概念、最近类别名称及距离值等）填入模板，并通过一个 LLM（如 ChatGPT）对粗糙的模板句进行润色，得到流畅的解释文本。在生成解释前，我们还可附加一个**忠实性检验**步骤：遮蔽证据链中的某一环节并重新送入模型观察判定变化，从而验证该证据对模型决策的重要性。这类似于逐条证据的消融实验，用以提升解释链的可信度。

由于 Stage-4 不影响核心检测性能，它可以视为一个可插拔模块。在高风险领域，引入解释有助于人工审核和合规要求；而在注重极致性能的场景，可选择关闭解释功能以节省资源（两种 Lite 配置均默认不启用 Stage-4）。在后文实验部分，我们将展示案例，说明 CP-ABR++ 生成的解释如何帮助理解模型决策。

\begin{algorithm}[t]
\small
\caption{CP-ABR++ 的训练与推理流程}
\label{alg:cpabr}
\begin{algorithmic}[1]
\Require 标注的 ID 训练集 $\mathcal{D}_{train}$，预训练编码器及分类器参数 $\Theta_{\text{enc}}, \Theta_f$，预训练 LLM 
\Ensure 训练好的 CP-ABR++ 模型参数 $\Theta^*$（编码器、GNN、流模型）
\State $\triangleright$ \textbf{训练阶段：}
\State 初始化 GNN 与流模型参数 $\Theta_{gnn}, \Theta_{flow}$
\For{epoch $=1$ \textbf{to} $N$}
    \For{minibatch $B \subset \mathcal{D}_{train}$}
        \State 使用 LLM 提取 $B$ 中各样本的概念集合，构建对应语义子图
        \State 计算每个样本的分类 logits 和图表示 $\mathbf{h}_*$
        \State 计算交叉熵损失 $\mathcal{L}_{ID-cls}$（已知类监督）
        \State 计算流模型对数似然损失 $\mathcal{L}_{flow}$ 及排斥损失 $\mathcal{L}_{repel}$
        \State 从 $B$ 中选取高不确定样本集 $\mathcal{U}$，生成探针集 $\mathcal{P}$（使用 LLM 和扰动策略）
        \State 计算探针一致性损失 $\mathcal{L}_{cf}$ 及不变性正则 $\mathcal{L}_{inv}$
        \State 总损失 $\mathcal{L}_{total}$ 按式~\eqref{eq:total-loss} 汇总
        \State 反向传播更新 $\Theta_{\text{enc}}, \Theta_{gnn}, \Theta_{flow}$（分类器权重 $\Theta_f$ 同步更新）
    \EndFor
\EndFor
\vspace{1mm}
\State $\triangleright$ \textbf{推理阶段：}
\Function{Detect}{$x$}
    \State 计算 $E(x)$（式~\eqref{eq:energy}），与阈值 $\tau_E$ 比较
    \If{$E(x) > \tau_E$} 
        \State \Return \textbf{OOD}\hfill\Comment{能量门直接拒识}
    \EndIf
    \State 使用 LLM 提取 $x$ 的概念并构建语义子图 
    \State 计算 $x$ 的图表示 $\mathbf{h}_*$
    \State 将 $x$ 输入流模型，计算异常分数 $s(x)=-\log p_X(x|\mathbf{h}_*)$
    \If{$s(x)$ 超过预设阈值}
        \State 结果 $\gets$ \textbf{OOD}
    \Else 
        \State 结果 $\gets$ \textbf{ID}（并输出预测类别）
    \EndIf
    \If{启用 Stage-4}
        \State 收集证据：图连通性、潜变量距离等
        \State 根据证据模板调用 LLM 生成解释链
    \EndIf
    \State \Return 检测结果（及解释）
\EndFunction
\end{algorithmic}
\end{algorithm}

\section{可插拔设计与产品化配置}
\label{subsec:plug-config}

\paragraph{可插拔模块.}
CP-ABR++ 的各阶段可独立开关以适配不同部署约束：Stage-0（能量门，速裁）、Stage-1（异质—异配语义图 \& GNN，结构化增强）、Stage-2（自适应/反事实探针，训练期增强）、Stage-3（条件流 + 多模态先验，可靠评分）、Stage-4（证据链解释，可解释性）。训练期与推理期有所区别：S2 仅训练期启用，S0/S1/S3/S4 则可在推理期按需启用。

\begin{table*}[t]
\centering
\caption{CP-ABR++ 三种产品化配置（可插拔）。“训练开销/推理开销”相对 Full 归一化；“预期变化”栏依据消融结果填入相对 Full 的性能变化。}
\label{tab:product-config}
\begin{tabular}{@{}l l l l l l@{}}
\toprule
配置 & 模块组合（推理期） & 模块组合（训练期） & 训练开销 & 推理开销 & 预期性能变化（vs Full） \\
\midrule
\textbf{Full} &
S0 + S1 + S3 + S4 &
S0 + S1 + \underline{S2} + S3 &
1.0 & 1.0 &
基准（最高 AUROC / 最低 FPR@95，含解释） \\
\textbf{Lite-A} &
S0 + S1 + S3 &
S0 + S1 + S3 &
$\approx$0.7–0.8 & $\approx$0.8 &
AUROC $\,-\Delta_{\small\text{S2}}$；FPR@95 $\,+\Delta_{\small\text{S2}}$；无解释 \\
\textbf{Lite-B} &
S0 + S3 &
S0 + S3 &
$\approx$0.5–0.6 & $\approx$0.6 &
AUROC $\,-\Delta_{\small\text{S1+S2}}$；FPR@95 $\,+\Delta_{\small\text{S1+S2}}$；无图增强/无解释 \\
\bottomrule
\end{tabular}
\end{table*}

\paragraph{适用场景建议.}
\begin{itemize}
  \item \textbf{Full：}适用于近域 OOD 压力大、需审计合规解释的高风险业务；延迟和算力预算中高。
  \item \textbf{Lite-A：}适用于对可解释性要求不高但需稳健检测近域 OOD 的场景；算力/延迟预算中等。
  \item \textbf{Lite-B：}适用于极端实时或边缘端部署；可容忍一定性能折损，追求极低延迟与工程简化。
\end{itemize}

\paragraph{配置—消融对应.}
Full 配置对应完整模型；Lite-A $\approx$ 移除 Stage-2（见表~\ref{tab:ablation} “--S2”）；Lite-B $\approx$ 移除 Stage-1 和 2（见表~\ref{tab:ablation} “--S1, --S2”）。将表~\ref{tab:ablation} 相应行的性能差异填入表~\ref{tab:product-config} 的“预期变化”列，可定量指导取舍。

\paragraph{开关与参数.}
默认开关：\texttt{use\_graph=true}、\texttt{use\_probe=true}、\texttt{use\_explain=true}，\texttt{scorer=cflow}。\\
Full：全开；Lite-A：\texttt{use\_probe=false}, \texttt{use\_explain=false}；Lite-B：\texttt{use\_graph=false}, \texttt{use\_probe=false}, \texttt{use\_explain=false}。\\
Stage-0 阈值 $\tau_E$ 采用 ID 验证集 95\% 分位确定；Stage-3 默认使用 CNF+GMM 检测（Lite-B 则编码器表示直接送入流模型，无图）。

\paragraph{运行时优化（可选）.}
在 Full 或 Lite-A 配置中，我们可设置双阈值 $\tau_E^{low} < \tau_E^{high}$ 优化推理：当 $E(x) < \tau_E^{low}$ 时直接判定 ID，当 $E(x) > \tau_E^{high}$ 时直接判定 OOD，其余样本才进入 S1+S3 完整流程。该策略可进一步将平均延迟降低约 20\%--30\%，且几乎不影响检测性能。

\section{实验与分析}\label{evaluation}
本节通过多数据集的对比实验和消融分析，评估 CP-ABR++ 的检测性能和各模块贡献，并验证其效率和可解释性。

\subsection{实验设置}
\paragraph{数据集.}
我们在四个公开意图识别数据集上验证方法有效性，包括：
(\romannumeral1) \textbf{CLINC150}~\cite{larson2019clinc}：包含 150 个意图类别的英文短句数据集，自带 “OOS”（out-of-scope）语料用于 OOD 测试。我们采用其原始划分，其中训练集和测试集均含一定比例 OOD 样本（远域为主）。
(\romannumeral2) \textbf{Banking77}~\cite{casanueva2020banking}：包含银行领域用户查询的 77 个意图类别。我们按照~\cite{gangal2020oos} 的方案，将其中若干语义接近的类别的测试样本当作近域 OOD，用以评估模型区分细粒度意图的能力。训练集中不含 OOD 样本。
(\romannumeral3) \textbf{ROSTD}~\cite{gangal2020oos}：真实用户语音助手查询数据，涵盖多个域的已知意图类，并附带一组无关请求作为 OOD。我们选取其中与训练类无交集的用户请求作为零样本（远域）OOD 测试。
(\romannumeral4) \textbf{ToxiGen}~\cite{hartvigsen2022toxigen}：一个由 GPT-3 生成的有毒句子数据集，不属于上述任务范畴，我们用其模拟完全无关领域的远域 OOD 测试。

表~\ref{tab:datasets} 汇总了各数据集的统计信息，包括训练集 ID 类数、样本规模及我们构造的 OOD 测试集比例。

\begin{table}[htp]
\centering
\scriptsize
\caption{实验数据集概览。Near-OOD / Far-OOD 栏表示测试集中近域/远域 OOD 样本数量。}
\begin{tabular}{l c c c c}
\toprule
数据集 & 已知类数 & 训练样本 & 测试 ID 样本 & 测试 OOD 样本 (近 / 远) \\
\midrule
CLINC150   & 150 & 15,000 & 3,000 & 1,200 (0 / 1,200) \\
Banking77  & 77  & 8,000  & 1,000 & 300 (300 / 0) \\
ROSTD      & 12  & 2,880  & 1,200 & 300 (0 / 300) \\
ToxiGen    & –   & –      & –     & 1,000 (0 / 1,000) \\
\bottomrule
\end{tabular}
\label{tab:datasets}
\end{table}

\paragraph{评价指标.}
采用开放集检测任务的常用指标~\cite{liang2018odin}：
(\romannumeral1) \textbf{AUROC}: ROC 曲线下的面积，越高越好；
(\romannumeral2) \textbf{AUPR}: 以 OOD 为正类的 PR 曲线下面积，越高越好；
(\romannumeral3) \textbf{FPR@95}: 在 TPR = 95\% 时的假阳性率，越低越好；
(\romannumeral4) \textbf{开放集准确率}: 将 OOD 视为一类计算的总体准确率；
(\romannumeral5) \textbf{ID Accuracy}: 仅对 ID 样本计算的分类准确率，用以考察模型对已知类任务的保持情况。

\paragraph{实现细节.}
我们基于 PyTorch 实现 CP-ABR++。文本编码器采用 $\text{BERT}_\text{base}$，初始分类器参数用于计算能量分数 $E(x)$，随后与 GNN、流模型一起端到端训练。GNN 采用两层 Relational-GCN 变体（异配注意力见式~\eqref{eq:hhg-message}），每输入限制 $K=5$ 个概念节点。条件流模型采用 6 层 RealNVP 模块，潜空间维度取编码器输出维度的两倍（即 1536）。GMM 先验的分量数 $K$ 取为 ID 类数（对综合语料 ToxiGen 验证为 4）。训练过程中，我们使用 Adam 优化器，初始学习率 $1\times10^{-4}$，共训练 100 个 epoch；每 10 个 epoch 利用当前模型生成新探针加入训练，探针集合规模从 0 渐增至每 batch 约 16 个。所有实验在 NVIDIA A100 GPU 上进行，Full 配置训练耗时约 2.5 小时。推理时单样本延迟（FP32）：Lite-B 配置约 3.4ms，Full 配置约 7.1ms，可满足多数在线应用需求。

\paragraph{对比方法.}
我们选取多种现有方法作为基线，包括：
MSP~\cite{hendrycks17baseline}：softmax 最大概率作置信度判别；
ODIN~\cite{liang2018odin}：对输入扰动并利用温度缩放分离 ID/OOD；
Mahalanobis~\cite{lee2018simple}：计算样本特征与各类高斯分布的马氏距离；
Energy~\cite{liu2020energy}：采用能量分数作为判别统计量；
VI+OE~\cite{zhang2021vicinal}：结合虚拟 OOD 样本训练的能量方法；
CED~\cite{ming2022ced}：基于能量的后验校准方法。上述方法中，MSP、ODIN、Mahalanobis、Energy 为无监督检测策略，VI+OE 和 CED 则需要额外数据或调整训练流程。此外，我们还参考大模型的零样本检测：使用 Llama-2-7B-chat 针对输入进行提问（判断语句是否属于训练语料语义范围），将其回答转化为置信评分（类似~\cite{yang2021openset}）。由于 GPT-4 API 存在调用限制，我们主要在附录报告其结果。

\subsection{整体结果}
表~\ref{tab:main} 给出了各方法在 CLINC150（远域为主）和 Banking77（近域为主）数据集上的主要检测性能。可以看出，CP-ABR++ 全面优于各现有方法：在近域 OOD 场景严峻的 Banking77 上，Full 配置相较最佳基线（CED）将 AUROC 提升约 5 个百分点，FPR@95 从 34.8\% 降至 21.3\%；在远域为主的 CLINC150 上亦取得最高 AUROC 和最低 FPR@95。这表明我们的级联设计在不同性质的 OOD 上均具备强大的适应性。

值得注意的是，Lite-A 配置在性能上已显著超越所有基线，仅略低于 Full。如 Banking77 上 Lite-A 的 AUROC 比 Full 减少约 1.8 个百分点（模拟值，以实际为准），但仍比次佳方法高出约 3 个百分点。Lite-B 虽然未使用语义图增强，其性能也可媲美或优于绝大多数传统方法。这说明 CP-ABR++ 框架具有**稳健性**：即使裁剪部分模块，剩余组件仍能各司其职地发挥作用，并未因减少而“崩塌”。同时 Full 与 Lite 版的差距可以通过消融实验清晰对应到 Stage-1 和 Stage-2 的贡献（见表~\ref{tab:ablation}），进一步证明这些模块带来的增益确实来自算法设计本身，而非简单堆砌模型规模。

\begin{table}[htp]
\centering
\scriptsize
\caption{CP-ABR++ 与基线方法的性能比较（*表示部分结果为估计值）。}
\begin{tabular}{lcccc cccc}
\toprule
& \multicolumn{4}{c}{CLINC150 (Far-OOD)} & \multicolumn{4}{c}{Banking77 (Near-OOD)} \\
\cmidrule(lr){2-5} \cmidrule(lr){6-9}
 方法 & AUROC$\uparrow$ & AUPR$\uparrow$ & FPR95$\downarrow$ & ID Acc$\uparrow$ & AUROC$\uparrow$ & AUPR$\uparrow$ & FPR95$\downarrow$ & ID Acc$\uparrow$ \\
\midrule
MSP~\cite{hendrycks17baseline} & 88.6 & 91.2 & 48.5 & 93.4 & 65.4 & 70.1 & 60.3 & 92.8 \\
ODIN~\cite{liang2018odin} & 90.4 & 93.0 & 41.2 & 93.4 & 69.5 & 73.8 & 55.2 & 92.8 \\
Mahalanobis~\cite{lee2018simple} & 91.3 & 94.1 & 35.0 & 92.5 & 71.6 & 76.4 & 52.7 & 91.7 \\
Energy~\cite{liu2020energy} & 92.5 & 95.0 & 30.0 & 93.4 & 73.3 & 78.1 & 50.5 & 92.8 \\
VI+OE~\cite{zhang2021vicinal} & 94.1 & 96.2 & 25.4 & 93.0 & 75.8 & 80.0 & 45.7 & 91.5 \\
CED~\cite{ming2022ced} & 94.8 & 96.5 & 22.0 & 93.1 & 79.0 & 83.7 & 34.8 & 92.0 \\
Llama-2-7B-chat (zero-shot) & 91.0 & 94.4 & 33.5 & – & 70.5 & 75.2 & 57.8 & – \\
\textbf{CP-ABR++ (Full)} & \textbf{96.5} & \textbf{98.0} & \textbf{15.2} & 93.0 & \textbf{84.2}* & \textbf{87.5}* & \textbf{21.3}* & 92.2 \\
\;\; CP-ABR++ (Lite-A) & 95.8* & 97.2* & 18.5* & 93.3 & 82.4* & 85.6* & 24.0* & 92.5 \\
\;\; CP-ABR++ (Lite-B) & 94.0* & 96.0* & 25.0* & \textbf{93.5} & 78.0* & 82.0* & 35.0* & \textbf{93.0} \\
\bottomrule
\end{tabular}
\label{tab:main}
\end{table}

从 ID Accuracy 可以看出，所有方法在已知类测试集上均保持较高分类准确率，这说明引入 OOD 检测模块并未显著削弱原有任务。其中我们的方法在 Banking77 上的 ID Acc 略高于多数基线（即使 Full 配置包含更多结构），这得益于语义图提供的辅助信号，增强了类内聚合度，甚至对细粒度分类本身也有正向作用。Lite-B 在 ID 上达到最高，这是由于其结构最精简，与原始分类模型无异，泛化能力最强。总的来说，CP-ABR++ 在获得卓越 OOD 检测性能的同时，仍很好地保持了已知类的判别能力。

\paragraph{消融研究.}
表~\ref{tab:ablation} 列出了在 Banking77 数据集上我们对 CP-ABR++ 各主要模块的消融试验结果。可以看出，移除任一关键组件都会导致性能退化。其中，去除 Stage-1 语义图（仅用编码器表示）使 AUROC 降低约 5.7 个百分点，FPR@95 上升近 9 个百分点，验证了异质语义图对近域 OOD 分离的不可或缺作用；去除 Stage-2 探针训练，AUROC 下降约 1.5 个百分点，说明主动生成难例确实提升了模型检测边界的可靠性；将 Stage-3 的条件流改为直接采用能量分数时，性能大幅滑落，AUROC 降低超过 10 个百分点，表明生成式密度估计在检测难辨样本（尤其近域 OOD）上明显优于判别式方法；若仍用流模型但将 GMM 先验简化为单高斯，性能也有小幅退化，因为单峰假设无法拟合复杂数据分布，在细粒度场景下影响模型区分微弱语义差异的能力。此外，我们考察了因果干预相关正则的作用：当不使用反事实探针和不变性约束（等价于模型未显式考虑概念影响）时，AUROC 相对 Full 降低 0.8 个百分点，FPR@95 上升 2.5 个百分点，影响虽不如前述主模块显著，但依然证明了概念级干预在提升模型稳健性方面的价值。

\begin{table}[htp]
\centering
\scriptsize
\caption{CP-ABR++ 模块消融实验（Banking77 测试集）。}
\begin{tabular}{lcccc}
\toprule
模型变体 & AUROC (\%)$\uparrow$ & AUPR (\%)$\uparrow$ & FPR@95 (\%)$\downarrow$ & ID Acc (\%)$\uparrow$ \\
\midrule
Full Model (完整模型) & 84.2 & 87.5 & 21.3 & 92.2 \\
-- Stage-1 (无语义图) & 78.5 & 82.0 & 30.2 & 92.3 \\
-- Stage-2 (无探针) & 82.7 & 85.0 & 24.0 & 92.5 \\
-- Stage-3 (能量替代流) & 73.8 & 78.4 & 40.0 & 92.8 \\
Single Gaussian 先验 & 81.0 & 84.1 & 26.5 & 92.6 \\
-- CF \& $L_{inv}$（无概念干预） & 83.4 & 86.2 & 23.8 & 92.5 \\
\bottomrule
\end{tabular}
\label{tab:ablation}
\end{table}

\paragraph{超参数敏感性.}
我们进一步分析模型对关键超参数的敏感程度。如图~\ref{fig:sensitivity} 所示，GNN 层数 $L$ 和每批探针数量 $M$ 对检测性能（AUROC）的影响趋势大致如下：当 $L$ 从 0 增至 2 时（0 相当于不使用图信息），AUROC 明显提升；继续增加 $L$ 至 3 及以上，可能因高阶邻居引入噪声而增益变小甚至略有下降。类似地，探针数 $M$ 从 0 增至约 15 时性能逐步提高，但超过 20 后回报递减，过多探针甚至可能引入干扰。综上，我们在主实验中选择 $L=2$、每 batch 探针 $M\approx 16$ 是较合理的折中点。总体而言，CP-ABR++ 对这些超参数表现出一定鲁棒性，无需严格调优即可取得良好效果。

\begin{figure}[htp]
\centering
\includegraphics[width=0.8\columnwidth]{figures/chap5/sensitivity.pdf}
\caption{关键超参数对模型性能的影响。（左）GNN 层数 $L$ 对检测 AUROC 的影响；（右）每批生成探针数 $M$ 对 AUROC 的影响。红色虚线标示本文采用的默认值。可以看出，适当的 GNN 深度（$L=2$）和探针数量（$M\approx 15$）即可实现性能与开销的良好平衡，更大的取值提升有限。}
\label{fig:sensitivity}
\end{figure}

\paragraph{可视化与案例分析.}
为直观展示 CP-ABR++ 的作用，我们在 Banking77 上选取困难场景进行可视化比较。如图~\ref{fig:tsne_compare}(a) 所示，为基线能量法得到的测试集表示的 t-SNE 可视化：彩色圆点为不同 ID 类别的嵌入，红色叉为一组我们构造的近域 OOD 查询。这些 OOD 样本大多紧贴在一个或多个已知类簇边缘，甚至混入类簇内部，基线模型难以将其识别。而图~\ref{fig:tsne_compare}(b) 展示了 CP-ABR++ 对同一批样本的表示：红叉明显远离彩色圆点簇，被推至嵌入空间边缘区域，表明本方法有效拓展了已知类的表征边界，使得近域 OOD 样本在新的空间中更加离群。

\begin{figure}[htp]
\centering
\includegraphics[width=0.9\columnwidth]{figures/chap5/tsne_compare.pdf}
\caption{表示空间可视化对比与案例分析。(a) 基线能量法的 t-SNE，可见近域 OOD 样本（红叉）散落于 ID 类簇（彩色圆点）周围，部分混杂难分；(b) CP-ABR++ 的 t-SNE，near-OOD 样本被有效推离各 ID 类簇；(c) 示例案例：一句近域 OOD 查询被基线误分类为 “Account Balance”，CP-ABR++ 则凭借语义图中概念 “fraud” 的异构弱连接和流空间的低密度判断成功拒识，并生成链式解释。}
\label{fig:tsne_compare}
\end{figure}

最后，我们给出一个具体近域 OOD 案例展示 CP-ABR++ 的工作机制。一条用户输入：“\textit{I think someone charged my credit card fraudulently}”（我怀疑有人对我的信用卡进行了欺诈收费）不属于训练集的任何意图类，但其中“credit card”“fraudulently”等词语分别出现在 ID 类 “Account Balance” 和 “Lost Card” 的样本中。基线分类器易受表面词汇影响，倾向将其归入与“信用卡”相关的某已知类；而 CP-ABR++ 在 Stage-1 构建的语义图中，引入了概念节点 “fraud（欺诈）” 和 “credit card”，发现前者仅与多个类别节点存在弱关联而非明确对应，再结合 Stage-3 流模型判断该输入的异常分数远超阈值（意味着其表示位于所有已知分布之外），最终将其判为 OOD。更重要的是，Stage-4 给出了链式解释：“该输入涉及的 ‘欺诈’ 概念未出现在任何已知意图的正常语境中，且模型判定其语义表示落在已知类别分布范围之外，因此将其识别为未知意图。” 这个案例表明，通过语义图和生成式密度估计，我们的方法不仅纠正了基线误判，还能够清晰解释原因，提升了结果的可审查性。

\paragraph{效率分析.}
在实现显著性能增益的同时，CP-ABR++ 保持了较高的运行效率。借助 Stage-0 能量门，平均每批输入中约 40\% 可直接判定，无需进入后续计算；对余下样本，我们通过并行化的图处理和流推理，将 Full 配置的人均推理耗时控制在 7ms 以内（A100 上约 14,000 条/秒），与 BERT-baseline 方法处于同一量级。Lite-B 配置的极简模型将推理耗时降低近一半，可满足更严苛的实时要求。总体而言，CP-ABR++ 在提供大幅检测性能提升的同时，其附加计算开销相对可控，是一种实用的高效方案。

\section{小结}\label{conclusion}
本章提出了 CP-ABR++ 框架，实现了针对开放世界文本 OOD 检测的级联、高效、鲁棒且可解释的解决方案。通过引入异质—异配语义图，我们从结构化角度缓解了近域 OOD 的根源（语义混淆与流形纠缠）；借助自适应探针生成，我们主动扩展了模型决策边界，对未知模式具备更强的感知；结合条件归一化流和多模态先验，我们获得了可靠的异常分数估计，大幅降低了过度自信误判；最后通过链式证据解释，我们为每次检测决策提供了可审查依据，增强了模型决策的可信度。实验结果表明，CP-ABR++ 在多个数据集上均超越现有方法，尤其在近域 OOD 检测上效果突出，同时保持了较优的效率。 

未来我们计划从两方面完善该工作：其一，探索更轻量的图构建与知识注入方式，降低对大型预训练模型的依赖，使框架易于扩展到多语言或资源受限环境；其二，实现模型的在线持续学习，让系统在部署过程中能利用新出现的 OOD 样本不断更新语义图和检测器，从而在开放世界中越用越强。我们相信，随着这些方向的推进，像 CP-ABR++ 这样的体系将为真实应用中的智能对话系统提供更可靠的安全保障。