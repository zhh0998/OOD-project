#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯• - éªŒè¯HeterophilyEnhanced v2æ˜¯å¦å·¥ä½œ

é¢„è®¡è¿è¡Œæ—¶é—´ï¼š5-10åˆ†é’Ÿ
"""

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent))

print("\nğŸš€ å¿«é€Ÿæµ‹è¯• HeterophilyEnhanced v2")
print("="*70)
sys.stdout.flush()

# Step 1: å¯¼å…¥æ£€æŸ¥
print("\n1ï¸âƒ£ æ£€æŸ¥ä¾èµ–...")
sys.stdout.flush()

try:
    import torch
    print(f"   âœ… PyTorch: {torch.__version__}")
except ImportError as e:
    print(f"   âŒ PyTorch: {e}")
    sys.exit(1)
sys.stdout.flush()

try:
    from torch_geometric.nn import GATv2Conv
    print(f"   âœ… PyTorch Geometric: GATv2Convå¯ç”¨")
except ImportError as e:
    print(f"   âŒ PyTorch Geometric: {e}")
    sys.exit(1)
sys.stdout.flush()

try:
    from sentence_transformers import SentenceTransformer
    print(f"   âœ… Sentence Transformers: å¯ç”¨")
except ImportError as e:
    print(f"   âŒ Sentence Transformers: {e}")
    sys.exit(1)
sys.stdout.flush()

# Step 2: åŠ è½½æ•°æ®ï¼ˆå°æ ·æœ¬ï¼‰
print("\n2ï¸âƒ£ åŠ è½½æµ‹è¯•æ•°æ®...")
sys.stdout.flush()
from data_loader import load_clinc150

train_texts, test_texts, test_labels, test_intents, train_labels = load_clinc150()

# åªç”¨å‰1000ä¸ªè®­ç»ƒæ ·æœ¬
train_texts = train_texts[:1000]
train_labels = train_labels[:1000]

# æµ‹è¯•æ ·æœ¬ï¼šå–å‰250 ID + å250 OODï¼ˆç¡®ä¿æœ‰OODæ ·æœ¬ï¼‰
import numpy as np
test_arr = np.array(test_labels)
id_idx = np.where(test_arr == 0)[0][:250]
ood_idx = np.where(test_arr == 1)[0][:250]
keep_idx = np.concatenate([id_idx, ood_idx])
test_texts = [test_texts[i] for i in keep_idx]
test_labels = [test_labels[i] for i in keep_idx]

print(f"   è®­ç»ƒé›†: {len(train_texts)} æ ·æœ¬")
print(f"   æµ‹è¯•é›†: {len(test_texts)} æ ·æœ¬")
sys.stdout.flush()

# Step 3: è·å–embeddings
print("\n3ï¸âƒ£ è·å–embeddings...")
sys.stdout.flush()
encoder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
train_emb = encoder.encode(train_texts, show_progress_bar=False)
test_emb = encoder.encode(test_texts, show_progress_bar=False)
print(f"   âœ… Embedding shape: {train_emb.shape}")
sys.stdout.flush()

# Step 4: æµ‹è¯•HeterophilyEnhanced v2
print("\n4ï¸âƒ£ æµ‹è¯•HeterophilyEnhanced v2...")
sys.stdout.flush()

try:
    from heterophily_enhanced_v2 import HeterophilyEnhancedV2

    detector = HeterophilyEnhancedV2(
        input_dim=train_emb.shape[1],
        hidden_dim=128,
        output_dim=64,
        k=30,
        num_layers=2,
        alpha=0.3
    )

    print("   è®­ç»ƒä¸­ï¼ˆ5 epochsï¼‰...")
    sys.stdout.flush()
    detector.fit(train_emb, train_labels, epochs=5, verbose=True)

    print("   è¯„ä¼°ä¸­...")
    sys.stdout.flush()
    scores = detector.score(test_emb)

    from quick_fix import evaluate_ood
    metrics = evaluate_ood(test_labels, scores)

    print(f"\n   âœ… AUROC: {metrics['auroc']:.2f}%")
    print(f"   FPR@95: {metrics['fpr95']:.2f}%")
    sys.stdout.flush()

    print("\nğŸ‰ HeterophilyEnhanced v2 å·¥ä½œæ­£å¸¸!")
    sys.stdout.flush()

except Exception as e:
    print(f"\n   âŒ å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# Step 5: å¯¹æ¯”KNNåŸºçº¿
print("\n5ï¸âƒ£ å¯¹æ¯”KNN-10åŸºçº¿...")
sys.stdout.flush()
from quick_fix import FixedKNNDetector

knn = FixedKNNDetector(k=10)
knn.fit(train_emb)
knn_scores, _ = knn.score_with_fix(test_emb, test_labels)
knn_metrics = evaluate_ood(test_labels, knn_scores)

print(f"   KNN-10 AUROC: {knn_metrics['auroc']:.2f}%")
sys.stdout.flush()

improvement = metrics['auroc'] - knn_metrics['auroc']
print(f"\nğŸ“Š æ”¹è¿›: {improvement:+.2f}%")
sys.stdout.flush()

if improvement > 0:
    print("   âœ… HeterophilyEnhancedè¶…è¿‡KNN!")
else:
    print("   âš ï¸ éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")

print("\n" + "="*70)
print("âœ… å¿«é€Ÿæµ‹è¯•å®Œæˆ!")
sys.stdout.flush()
